# -*- coding: utf-8 -*-
"""MJAhmadi_NNDL_ExtraHW_Q1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CuLFCg0TqnZf76EFZoQ2U4Ye96GaunzE
"""

!pip install --upgrade --no-cache-dir gdown
!gdown 1Mr_42LL7uikdXZskQAUcZkzNRmZmWDLa
!gdown 1vZ14P6HjWSvJ0pIamm5vLQFN9108vNWg

"""# 1&2.Data Processing"""

import pandas as pd
import matplotlib.pyplot as plt

# Load data from CSV file
data = pd.read_csv('/content/Litecoin.csv')

# Convert 'Date' column to datetime format
data['Date'] = pd.to_datetime(data['Date'])

# Plot prices vs. time
plt.plot(data['Date'], data['Price'], label='Price')

# Highlight highest and lowest prices with red and blue points
highest_price = data.loc[data['High'].idxmax(), 'Price']
lowest_price = data.loc[data['Low'].idxmin(), 'Price']
plt.plot(data.loc[data['High'].idxmax(), 'Date'], highest_price, 'ro', markersize=10, label='Highest: $' + str(highest_price))
plt.plot(data.loc[data['Low'].idxmin(), 'Date'], lowest_price, 'bo', markersize=10, label='Lowest: $' + str(lowest_price))

# Plot average with dash-line
average_price = data['Price'].mean()
plt.axhline(average_price, linestyle='--', color='gray', label='Average: $' + str(round(average_price, 2)))

# Format plot
plt.title('Litecoin Prices (USD) vs. Time')
plt.xlabel('Date')
plt.ylabel('Price (USD)')
plt.legend()

# Save plot as PDF
plt.savefig('Litecoin Prices.pdf')

import pandas as pd
import matplotlib.pyplot as plt

# Load data from CSV file
data = pd.read_csv('/content/Monero.csv')

# Convert 'Date' column to datetime format
data['Date'] = pd.to_datetime(data['Date'])

# Plot prices vs. time
plt.plot(data['Date'], data['Price'], label='Price')

# Highlight highest and lowest prices with red and blue points
highest_price = data.loc[data['High'].idxmax(), 'Price']
lowest_price = data.loc[data['Low'].idxmin(), 'Price']
plt.plot(data.loc[data['High'].idxmax(), 'Date'], highest_price, 'ro', markersize=10, label='Highest: $' + str(highest_price))
plt.plot(data.loc[data['Low'].idxmin(), 'Date'], lowest_price, 'bo', markersize=10, label='Lowest: $' + str(lowest_price))

# Plot average with dash-line
average_price = data['Price'].mean()
plt.axhline(average_price, linestyle='--', color='gray', label='Average: $' + str(round(average_price, 2)))

# Format plot
plt.title('Monero Prices (USD) vs. Time')
plt.xlabel('Date')
plt.ylabel('Price (USD)')
plt.legend()

# Save plot as PDF
plt.savefig('Monero Prices.pdf')

import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# Load data from CSV file
data = pd.read_csv('/content/Litecoin.csv')

# Convert string values to numeric values in the 'Vol.' column.
def convert_vol(vol):
    if vol.endswith('M'):
        return int(float(vol[:-1]) * 1000000)
    elif vol.endswith('K'):
        return int(float(vol[:-1]) * 1000)
    else:
        return int(vol)

data['Vol.'] = data['Vol.'].apply(convert_vol)
data['Change %'] = data['Change %'].str.replace('%', '').astype(float)

# Select the primary feature for training
training_data = data['Price'].values.reshape(-1, 1)

# Normalize the training data to scale values between 0 and 1
scaler = MinMaxScaler(feature_range=(0, 1))
training_data_normalized = scaler.fit_transform(training_data)

# Define the input window length (number of past days to use for prediction)
input_window_length = 30

# Use the PROCESS_DATA algorithm to create input/output samples
def process_data(data, input_window_length):
    Dx = []
    Dy = []
    n = len(data)
    for i in range(n):
        end_index = i + input_window_length
        if end_index > n-1:
            break
        temp_X = data[i:end_index, :]
        temp_Y = data[end_index, :]
        Dx.append(temp_X)
        Dy.append(temp_Y)
    return (Dx, Dy)

# Create input/output samples using the training data
train_X, train_Y = process_data(training_data_normalized, input_window_length)

# Split the data into training and testing sets (use 80/20 split)
split_index = int(len(train_X)*0.8)
train_X, test_X = train_X[:split_index], train_X[split_index:]
train_Y, test_Y = train_Y[:split_index], train_Y[split_index:]

import pandas as pd

# Load the data from the csv file
df = pd.read_csv('/content/Litecoin.csv')

# Print the first two rows
print('A:')
print(df.head(5))

def convert_vol(vol):
    if vol.endswith('M'):
        return int(float(vol[:-1]) * 1000000)
    elif vol.endswith('K'):
        return int(float(vol[:-1]) * 1000)
    else:
        return int(vol)

df['Vol.'] = df['Vol.'].apply(convert_vol)
df['Change %'] = df['Change %'].str.replace('%', '').astype(float)
print('B:')
print(df.head(5))

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from tensorflow.keras.models import Sequential
from keras.layers import Dense, Conv1D, MaxPooling1D , Dropout , Flatten , BatchNormalization,LSTM
from tensorflow.keras.optimizers import SGD,Adam
from sklearn.metrics import confusion_matrix
import pandas as pd 
from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
import warnings
warnings.filterwarnings('ignore')

# Load the data from the csv file
df = pd.read_csv('/content/Litecoin.csv')

# Print the first two rows
print('A:')
print(df.head(5))

def convert_vol(vol):
    if vol.endswith('M'):
        return int(float(vol[:-1]) * 1000000)
    elif vol.endswith('K'):
        return int(float(vol[:-1]) * 1000)
    else:
        return int(vol)

df['Vol.'] = df['Vol.'].apply(convert_vol)
df['Change %'] = df['Change %'].str.replace('%', '').astype(float)
print('B:')
print(df.head(5))

#  Read dataset
df=df[['Price','Open','High','Low','Vol.','Change %']]
df.shape
df.head()

import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files

plt.figure(figsize=(7,5))
sns.heatmap(df.corr(),annot=True,cmap=plt.cm.Blues)

plt.savefig('heatmap.pdf', format='pdf', bbox_inches='tight')
files.download('heatmap.pdf')

import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize=(7,5))
df[['Price','Open','High','Low','Vol.','Change %']].plot(ax=ax, subplots=True)
plt.savefig('plot.pdf', format='pdf', dpi=300, bbox_inches='tight')

df=df[['Price']]
df.shape
df.head()

# Scale the data using MinMaxScaler with range (0,1)
scaler = MinMaxScaler(feature_range=(0,1))
df = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)
df.head()

def fun(data, lag):
    """
    A function that takes in data and a lag value and returns two arrays: x and y.
    x is an array of shape (k, lag, n), where k is the number of samples and n is the number of features.
    y is an array of shape (k, 1), where k is the number of samples.
    Each sample in x is a sequence of lag consecutive observations from data, and the corresponding value in y is the next observation.
    """
    k = len(data) - lag
    x = []
    y = []
    for i in range(k):
        x.append(data[i:i+lag])
        y.append(data[i+lag,:1])
    x = np.array(x)
    y = np.array(y)
    return x, y

# Reverse the order of the data array
data = np.array(df.iloc[::-1])

# Split the data into train and test sets
test = data[-31:]
train = data[:-30]

# Set the lag value
lag = 30

# Use the function fun to create x_train, y_train, x_test, and y_test arrays
x_train, y_train = fun(train, lag)
x_test, y_test = fun(test, lag)

# print x_test and y_test data
print("x_test data:\n", x_test)
print("y_test data:\n", y_test)

# print x_test and y_test shape
print("x_test shape:", x_test.shape)
print("y_test shape:", y_test.shape)

# print x_test and y_test data
print("x_test data:\n", x_test)
print("y_test data:\n", y_test)

# print x_test and y_test shape
print("x_test shape:", x_test.shape)
print("y_test shape:", y_test.shape)

"""# 3. Train Model

## Approach 1

### HYBRID
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Model
from keras.layers import Input, GRU, LSTM, Dense, Dropout, concatenate
from keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error
from matplotlib.backends.backend_pdf import PdfPages
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, GRU, Dropout, Dense, concatenate
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt

# Load data from CSV file
data = pd.read_csv('/content/Litecoin.csv')

# Convert string values to numeric values in the 'Vol.' column.
def convert_vol(vol):
    if vol.endswith('M'):
        return int(float(vol[:-1]) * 1000000)
    elif vol.endswith('K'):
        return int(float(vol[:-1]) * 1000)
    else:
        return int(vol)

data['Vol.'] = data['Vol.'].apply(convert_vol)
data['Change %'] = data['Change %'].str.replace('%', '').astype(float)

# Select the primary feature for training
training_data = data['Price'].values.reshape(-1, 1)

# Normalize the training data to scale values between 0 and 1
scaler = MinMaxScaler(feature_range=(0, 1))
training_data_normalized = scaler.fit_transform(training_data)

# Define the input window length (number of past days to use for prediction)
input_window_length = 30

# Use the PROCESS_DATA algorithm to create input/output samples
def process_data(data, input_window_length):
    Dx = []
    Dy = []
    n = len(data)
    for i in range(n):
        end_index = i + input_window_length
        if end_index > n-1:
            break
        temp_X = data[i:end_index, :]
        temp_Y = data[end_index, 0]
        Dx.append(temp_X)
        Dy.append(temp_Y)
    Dx = np.array(Dx)
    Dy = np.array(Dy)
    return (Dx, Dy)

# Create input/output samples using the training data
train_X, train_Y = process_data(training_data_normalized, input_window_length)

# Split the data into training and testing sets (use 80/20 split)
split_index = int(len(train_X)*0.8)
train_X, test_X = train_X[:split_index], train_X[split_index:]
train_Y, test_Y = train_Y[:split_index], train_Y[split_index:]

# Define the model
inputs = Input(shape=(input_window_length, 1))

# GRU Network
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.2)(gru)
gru = Dense(32, activation='relu')(gru)

# LSTM Network
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.2)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(32, activation='relu')(lstm)

# Combine GRU and LSTM networks
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)

model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer='adam', loss='mse', metrics=['mae','mse'])

# Train the model
early_stop = EarlyStopping(monitor='val_loss', patience=5)
history = model.fit(train_X, train_Y, epochs=100, validation_split=0.2, batch_size=32, callbacks=[early_stop])

# Plot MAE over epochs
mae_history = history.history['mae']
val_mae_history = history.history['val_mae']
plt.plot(range(1, len(mae_history)+1), mae_history, label='Training MAE')
plt.plot(range(1, len(val_mae_history)+1), val_mae_history, label='Validation MAE')
plt.title('Training and Validation MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()
plt.savefig('maeplot.pdf')
plt.show()

# Plot MSE over epochs
mse_history = history.history['loss']
val_mse_history = history.history['val_loss']
plt.plot(range(1, len(mse_history)+1), mse_history, label='Training MSE')
plt.plot(range(1, len(val_mse_history)+1), val_mse_history, label='Validation MSE')
plt.title('Training and Validation MSE')
plt.xlabel('Epoch')
plt.ylabel('MSE')
plt.legend()
plt.savefig('mseplot.pdf')
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Model
from keras.layers import Input, GRU, LSTM, Dense, Dropout, concatenate
from keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error
from matplotlib.backends.backend_pdf import PdfPages
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, GRU, Dropout, Dense, concatenate
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt

# Load data from CSV file
data = pd.read_csv('/content/Monero.csv')

# Select the primary feature for training
training_data = data['Price'].values.reshape(-1, 1)

# Normalize the training data to scale values between 0 and 1
scaler = MinMaxScaler(feature_range=(0, 1))
training_data_normalized = scaler.fit_transform(training_data)

# Define the input window length (number of past days to use for prediction)
input_window_length = 30

# Use the PROCESS_DATA algorithm to create input/output samples
def process_data(data, input_window_length):
    Dx = []
    Dy = []
    n = len(data)
    for i in range(n):
        end_index = i + input_window_length
        if end_index > n-1:
            break
        temp_X = data[i:end_index, :]
        temp_Y = data[end_index, 0]
        Dx.append(temp_X)
        Dy.append(temp_Y)
    Dx = np.array(Dx)
    Dy = np.array(Dy)
    return (Dx, Dy)

# Create input/output samples using the training data
train_X, train_Y = process_data(training_data_normalized, input_window_length)

# Split the data into training and testing sets (use 80/20 split)
split_index = int(len(train_X)*0.8)
train_X, test_X = train_X[:split_index], train_X[split_index:]
train_Y, test_Y = train_Y[:split_index], train_Y[split_index:]

# Define the model
inputs = Input(shape=(input_window_length, 1))

# GRU Network
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.2)(gru)
gru = Dense(32, activation='relu')(gru)

# LSTM Network
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.2)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(32, activation='relu')(lstm)

# Combine GRU and LSTM networks
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)

model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer='adam', loss='mse', metrics=['mae','mse'])

# Train the model
early_stop = EarlyStopping(monitor='val_loss', patience=5)
history = model.fit(train_X, train_Y, epochs=100, validation_split=0.2, batch_size=32, callbacks=[early_stop])

# Plot MAE over epochs
mae_history = history.history['mae']
val_mae_history = history.history['val_mae']
plt.plot(range(1, len(mae_history)+1), mae_history, label='Training MAE')
plt.plot(range(1, len(val_mae_history)+1), val_mae_history, label='Validation MAE')
plt.title('Training and Validation MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()
plt.savefig('mmaeplot.pdf')
plt.show()

# Plot MSE over epochs
mse_history = history.history['loss']
val_mse_history = history.history['val_loss']
plt.plot(range(1, len(mse_history)+1), mse_history, label='Training MSE')
plt.plot(range(1, len(val_mse_history)+1), val_mse_history, label='Validation MSE')
plt.title('Training and Validation MSE')
plt.xlabel('Epoch')
plt.ylabel('MSE')
plt.legend()
plt.savefig('mmseplot.pdf')
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Model
from keras.layers import Input, GRU, LSTM, Dense, Dropout, concatenate
from keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error
from matplotlib.backends.backend_pdf import PdfPages
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, GRU, Dropout, Dense, concatenate
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt

# Load data from CSV file
data = pd.read_csv('/content/Litecoin.csv')

# Convert string values to numeric values in the 'Vol.' column.
def convert_vol(vol):
    if vol.endswith('M'):
        return int(float(vol[:-1]) * 1000000)
    elif vol.endswith('K'):
        return int(float(vol[:-1]) * 1000)
    else:
        return int(vol)

data['Vol.'] = data['Vol.'].apply(convert_vol)
data['Change %'] = data['Change %'].str.replace('%', '').astype(float)

# Select the primary feature for training
training_data = data['Price'].values.reshape(-1, 1)

# Normalize the training data to scale values between 0 and 1
scaler = MinMaxScaler(feature_range=(0, 1))
training_data_normalized = scaler.fit_transform(training_data)

# Define the input window length (number of past days to use for prediction)
input_window_length = 30

# Use the PROCESS_DATA algorithm to create input/output samples
def process_data(data, input_window_length):
    Dx = []
    Dy = []
    n = len(data)
    for i in range(n):
        end_index = i + input_window_length
        if end_index > n-1:
            break
        temp_X = data[i:end_index, :]
        temp_Y = data[end_index, 0]
        Dx.append(temp_X)
        Dy.append(temp_Y)
    Dx = np.array(Dx)
    Dy = np.array(Dy)
    return (Dx, Dy)

# Create input/output samples using the training data
train_X, train_Y = process_data(training_data_normalized, input_window_length)

# Split the data into training and testing sets (use 80/20 split)
split_index = int(len(train_X)*0.8)
train_X, test_X = train_X[:split_index], train_X[split_index:]
train_Y, test_Y = train_Y[:split_index], train_Y[split_index:]

# Define the model
inputs = Input(shape=(input_window_length, 1))

# GRU Network
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.2)(gru)
gru = Dense(32, activation='relu')(gru)

# LSTM Network
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.2)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(32, activation='relu')(lstm)

# Combine GRU and LSTM networks
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)

model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer='adam', loss='mse', metrics=['mae','mse'])

# Train the model
history = model.fit(train_X, train_Y, epochs=100, validation_split=0.2, batch_size=32)

# Plot MAE over epochs
mae_history = history.history['mae']
val_mae_history = history.history['val_mae']
plt.plot(range(1, len(mae_history)+1), mae_history, label='Training MAE')
plt.plot(range(1, len(val_mae_history)+1), val_mae_history, label='Validation MAE')
plt.title('Training and Validation MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()
plt.savefig('maeplot2.pdf')
plt.show()

# Plot MSE over epochs
mse_history = history.history['loss']
val_mse_history = history.history['val_loss']
plt.plot(range(1, len(mse_history)+1), mse_history, label='Training MSE')
plt.plot(range(1, len(val_mse_history)+1), val_mse_history, label='Validation MSE')
plt.title('Training and Validation MSE')
plt.xlabel('Epoch')
plt.ylabel('MSE')
plt.legend()
plt.savefig('mseplot2.pdf')
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Model
from keras.layers import Input, GRU, LSTM, Dense, Dropout, concatenate
from keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error
from matplotlib.backends.backend_pdf import PdfPages
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, GRU, Dropout, Dense, concatenate
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt

# Load data from CSV file
data = pd.read_csv('/content/Monero.csv')

# Select the primary feature for training
training_data = data['Price'].values.reshape(-1, 1)

# Normalize the training data to scale values between 0 and 1
scaler = MinMaxScaler(feature_range=(0, 1))
training_data_normalized = scaler.fit_transform(training_data)

# Define the input window length (number of past days to use for prediction)
input_window_length = 30

# Use the PROCESS_DATA algorithm to create input/output samples
def process_data(data, input_window_length):
    Dx = []
    Dy = []
    n = len(data)
    for i in range(n):
        end_index = i + input_window_length
        if end_index > n-1:
            break
        temp_X = data[i:end_index, :]
        temp_Y = data[end_index, 0]
        Dx.append(temp_X)
        Dy.append(temp_Y)
    Dx = np.array(Dx)
    Dy = np.array(Dy)
    return (Dx, Dy)

# Create input/output samples using the training data
train_X, train_Y = process_data(training_data_normalized, input_window_length)

# Split the data into training and testing sets (use 80/20 split)
split_index = int(len(train_X)*0.8)
train_X, test_X = train_X[:split_index], train_X[split_index:]
train_Y, test_Y = train_Y[:split_index], train_Y[split_index:]

# Define the model
inputs = Input(shape=(input_window_length, 1))

# GRU Network
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.2)(gru)
gru = Dense(32, activation='relu')(gru)

# LSTM Network
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.2)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(32, activation='relu')(lstm)

# Combine GRU and LSTM networks
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)

model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer='adam', loss='mse', metrics=['mae','mse'])

# Train the model
history = model.fit(train_X, train_Y, epochs=100, validation_split=0.2, batch_size=32)

# Plot MAE over epochs
mae_history = history.history['mae']
val_mae_history = history.history['val_mae']
plt.plot(range(1, len(mae_history)+1), mae_history, label='Training MAE')
plt.plot(range(1, len(val_mae_history)+1), val_mae_history, label='Validation MAE')
plt.title('Training and Validation MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()
plt.savefig('mmaeplot2.pdf')
plt.show()

# Plot MSE over epochs
mse_history = history.history['loss']
val_mse_history = history.history['val_loss']
plt.plot(range(1, len(mse_history)+1), mse_history, label='Training MSE')
plt.plot(range(1, len(val_mse_history)+1), val_mse_history, label='Validation MSE')
plt.title('Training and Validation MSE')
plt.xlabel('Epoch')
plt.ylabel('MSE')
plt.legend()
plt.savefig('mmseplot2.pdf')
plt.show()

"""### LSTM"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Model
from keras.layers import Input, GRU, LSTM, Dense, Dropout, concatenate
from keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error
from matplotlib.backends.backend_pdf import PdfPages
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, GRU, Dropout, Dense, concatenate
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt

# Load data from CSV file
data = pd.read_csv('/content/Litecoin.csv')

# Convert string values to numeric values in the 'Vol.' column.
def convert_vol(vol):
    if vol.endswith('M'):
        return int(float(vol[:-1]) * 1000000)
    elif vol.endswith('K'):
        return int(float(vol[:-1]) * 1000)
    else:
        return int(vol)

data['Vol.'] = data['Vol.'].apply(convert_vol)
data['Change %'] = data['Change %'].str.replace('%', '').astype(float)

# Select the primary feature for training
training_data = data['Price'].values.reshape(-1, 1)

# Normalize the training data to scale values between 0 and 1
scaler = MinMaxScaler(feature_range=(0, 1))
training_data_normalized = scaler.fit_transform(training_data)

# Define the input window length (number of past days to use for prediction)
input_window_length = 30

# Use the PROCESS_DATA algorithm to create input/output samples
def process_data(data, input_window_length):
    Dx = []
    Dy = []
    n = len(data)
    for i in range(n):
        end_index = i + input_window_length
        if end_index > n-1:
            break
        temp_X = data[i:end_index, :]
        temp_Y = data[end_index, 0]
        Dx.append(temp_X)
        Dy.append(temp_Y)
    Dx = np.array(Dx)
    Dy = np.array(Dy)
    return (Dx, Dy)

# Create input/output samples using the training data
train_X, train_Y = process_data(training_data_normalized, input_window_length)

# Split the data into training and testing sets (use 80/20 split)
split_index = int(len(train_X)*0.8)
train_X, test_X = train_X[:split_index], train_X[split_index:]
train_Y, test_Y = train_Y[:split_index], train_Y[split_index:]

# Define the model
inputs = Input(shape=(input_window_length, 1))

# LSTM Network
lstm = LSTM(50, activation='relu', return_sequences=True)(inputs)
outputs = Dense(1)(lstm)

model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer='adam', loss='mse', metrics=['mae','mse'])

# Train the model
early_stop = EarlyStopping(monitor='val_loss', patience=5)
history = model.fit(train_X, train_Y, epochs=100, validation_split=0.2, batch_size=32, callbacks=[early_stop])

# Plot MAE over epochs
mae_history = history.history['mae']
val_mae_history = history.history['val_mae']
plt.plot(range(1, len(mae_history)+1), mae_history, label='Training MAE')
plt.plot(range(1, len(val_mae_history)+1), val_mae_history, label='Validation MAE')
plt.title('Training and Validation MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()
plt.savefig('maeplot.pdf')
plt.show()

# Plot MSE over epochs
mse_history = history.history['loss']
val_mse_history = history.history['val_loss']
plt.plot(range(1, len(mse_history)+1), mse_history, label='Training MSE')
plt.plot(range(1, len(val_mse_history)+1), val_mse_history, label='Validation MSE')
plt.title('Training and Validation MSE')
plt.xlabel('Epoch')
plt.ylabel('MSE')
plt.legend()
plt.savefig('mseplot.pdf')
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Model
from keras.layers import Input, GRU, LSTM, Dense, Dropout, concatenate
from keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error
from matplotlib.backends.backend_pdf import PdfPages
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, GRU, Dropout, Dense, concatenate
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt

# Load data from CSV file
data = pd.read_csv('/content/Monero.csv')

# Select the primary feature for training
training_data = data['Price'].values.reshape(-1, 1)

# Normalize the training data to scale values between 0 and 1
scaler = MinMaxScaler(feature_range=(0, 1))
training_data_normalized = scaler.fit_transform(training_data)

# Define the input window length (number of past days to use for prediction)
input_window_length = 30

# Use the PROCESS_DATA algorithm to create input/output samples
def process_data(data, input_window_length):
    Dx = []
    Dy = []
    n = len(data)
    for i in range(n):
        end_index = i + input_window_length
        if end_index > n-1:
            break
        temp_X = data[i:end_index, :]
        temp_Y = data[end_index, 0]
        Dx.append(temp_X)
        Dy.append(temp_Y)
    Dx = np.array(Dx)
    Dy = np.array(Dy)
    return (Dx, Dy)

# Create input/output samples using the training data
train_X, train_Y = process_data(training_data_normalized, input_window_length)

# Split the data into training and testing sets (use 80/20 split)
split_index = int(len(train_X)*0.8)
train_X, test_X = train_X[:split_index], train_X[split_index:]
train_Y, test_Y = train_Y[:split_index], train_Y[split_index:]

# Define the model
inputs = Input(shape=(input_window_length, 1))

# LSTM Network
lstm = LSTM(50, activation='relu', return_sequences=True)(inputs)
outputs = Dense(1)(lstm)

model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer='adam', loss='mse', metrics=['mae','mse'])

# Train the model
early_stop = EarlyStopping(monitor='val_loss', patience=5)
history = model.fit(train_X, train_Y, epochs=100, validation_split=0.2, batch_size=32, callbacks=[early_stop])

# Plot MAE over epochs
mae_history = history.history['mae']
val_mae_history = history.history['val_mae']
plt.plot(range(1, len(mae_history)+1), mae_history, label='Training MAE')
plt.plot(range(1, len(val_mae_history)+1), val_mae_history, label='Validation MAE')
plt.title('Training and Validation MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()
plt.savefig('mmaeplot.pdf')
plt.show()

# Plot MSE over epochs
mse_history = history.history['loss']
val_mse_history = history.history['val_loss']
plt.plot(range(1, len(mse_history)+1), mse_history, label='Training MSE')
plt.plot(range(1, len(val_mse_history)+1), val_mse_history, label='Validation MSE')
plt.title('Training and Validation MSE')
plt.xlabel('Epoch')
plt.ylabel('MSE')
plt.legend()
plt.savefig('mmseplot.pdf')
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Model
from keras.layers import Input, GRU, LSTM, Dense, Dropout, concatenate
from keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error
from matplotlib.backends.backend_pdf import PdfPages
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, GRU, Dropout, Dense, concatenate
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt

# Load data from CSV file
data = pd.read_csv('/content/Litecoin.csv')

# Convert string values to numeric values in the 'Vol.' column.
def convert_vol(vol):
    if vol.endswith('M'):
        return int(float(vol[:-1]) * 1000000)
    elif vol.endswith('K'):
        return int(float(vol[:-1]) * 1000)
    else:
        return int(vol)

data['Vol.'] = data['Vol.'].apply(convert_vol)
data['Change %'] = data['Change %'].str.replace('%', '').astype(float)

# Select the primary feature for training
training_data = data['Price'].values.reshape(-1, 1)

# Normalize the training data to scale values between 0 and 1
scaler = MinMaxScaler(feature_range=(0, 1))
training_data_normalized = scaler.fit_transform(training_data)

# Define the input window length (number of past days to use for prediction)
input_window_length = 30

# Use the PROCESS_DATA algorithm to create input/output samples
def process_data(data, input_window_length):
    Dx = []
    Dy = []
    n = len(data)
    for i in range(n):
        end_index = i + input_window_length
        if end_index > n-1:
            break
        temp_X = data[i:end_index, :]
        temp_Y = data[end_index, 0]
        Dx.append(temp_X)
        Dy.append(temp_Y)
    Dx = np.array(Dx)
    Dy = np.array(Dy)
    return (Dx, Dy)

# Create input/output samples using the training data
train_X, train_Y = process_data(training_data_normalized, input_window_length)

# Split the data into training and testing sets (use 80/20 split)
split_index = int(len(train_X)*0.8)
train_X, test_X = train_X[:split_index], train_X[split_index:]
train_Y, test_Y = train_Y[:split_index], train_Y[split_index:]

# Define the model
inputs = Input(shape=(input_window_length, 1))

# LSTM Network
lstm = LSTM(50, activation='relu', return_sequences=True)(inputs)
outputs = Dense(1)(lstm)

model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer='adam', loss='mse', metrics=['mae','mse'])

# Train the model
history = model.fit(train_X, train_Y, epochs=100, validation_split=0.2, batch_size=32)

# Plot MAE over epochs
mae_history = history.history['mae']
val_mae_history = history.history['val_mae']
plt.plot(range(1, len(mae_history)+1), mae_history, label='Training MAE')
plt.plot(range(1, len(val_mae_history)+1), val_mae_history, label='Validation MAE')
plt.title('Training and Validation MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()
plt.savefig('maeplot2.pdf')
plt.show()

# Plot MSE over epochs
mse_history = history.history['loss']
val_mse_history = history.history['val_loss']
plt.plot(range(1, len(mse_history)+1), mse_history, label='Training MSE')
plt.plot(range(1, len(val_mse_history)+1), val_mse_history, label='Validation MSE')
plt.title('Training and Validation MSE')
plt.xlabel('Epoch')
plt.ylabel('MSE')
plt.legend()
plt.savefig('mseplot2.pdf')
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Model
from keras.layers import Input, GRU, LSTM, Dense, Dropout, concatenate
from keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error
from matplotlib.backends.backend_pdf import PdfPages
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, GRU, Dropout, Dense, concatenate
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt

# Load data from CSV file
data = pd.read_csv('/content/Monero.csv')

# Select the primary feature for training
training_data = data['Price'].values.reshape(-1, 1)

# Normalize the training data to scale values between 0 and 1
scaler = MinMaxScaler(feature_range=(0, 1))
training_data_normalized = scaler.fit_transform(training_data)

# Define the input window length (number of past days to use for prediction)
input_window_length = 30

# Use the PROCESS_DATA algorithm to create input/output samples
def process_data(data, input_window_length):
    Dx = []
    Dy = []
    n = len(data)
    for i in range(n):
        end_index = i + input_window_length
        if end_index > n-1:
            break
        temp_X = data[i:end_index, :]
        temp_Y = data[end_index, 0]
        Dx.append(temp_X)
        Dy.append(temp_Y)
    Dx = np.array(Dx)
    Dy = np.array(Dy)
    return (Dx, Dy)

# Create input/output samples using the training data
train_X, train_Y = process_data(training_data_normalized, input_window_length)

# Split the data into training and testing sets (use 80/20 split)
split_index = int(len(train_X)*0.8)
train_X, test_X = train_X[:split_index], train_X[split_index:]
train_Y, test_Y = train_Y[:split_index], train_Y[split_index:]

# Define the model
inputs = Input(shape=(input_window_length, 1))

# LSTM Network
lstm = LSTM(50, activation='relu', return_sequences=True)(inputs)
outputs = Dense(1)(lstm)

model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer='adam', loss='mse', metrics=['mae','mse'])

# Train the model
history = model.fit(train_X, train_Y, epochs=100, validation_split=0.2, batch_size=32)

# Plot MAE over epochs
mae_history = history.history['mae']
val_mae_history = history.history['val_mae']
plt.plot(range(1, len(mae_history)+1), mae_history, label='Training MAE')
plt.plot(range(1, len(val_mae_history)+1), val_mae_history, label='Validation MAE')
plt.title('Training and Validation MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()
plt.savefig('mmaeplot2.pdf')
plt.show()

# Plot MSE over epochs
mse_history = history.history['loss']
val_mse_history = history.history['val_loss']
plt.plot(range(1, len(mse_history)+1), mse_history, label='Training MSE')
plt.plot(range(1, len(val_mse_history)+1), val_mse_history, label='Validation MSE')
plt.title('Training and Validation MSE')
plt.xlabel('Epoch')
plt.ylabel('MSE')
plt.legend()
plt.savefig('mmseplot2.pdf')
plt.show()

"""# 4. Prediction

## Litecoin
"""

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from tensorflow.keras.models import Sequential
from keras.layers import Dense, Conv1D, MaxPooling1D , Dropout , Flatten , BatchNormalization,LSTM
from tensorflow.keras.optimizers import SGD,Adam
from sklearn.metrics import confusion_matrix
import pandas as pd 
from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
import warnings
warnings.filterwarnings('ignore')

# Load the data from the csv file
df = pd.read_csv('/content/Litecoin.csv')

# Print the first two rows
print('A:')
print(df.head(5))

def convert_vol(vol):
    if vol.endswith('M'):
        return int(float(vol[:-1]) * 1000000)
    elif vol.endswith('K'):
        return int(float(vol[:-1]) * 1000)
    else:
        return int(vol)

df['Vol.'] = df['Vol.'].apply(convert_vol)
df['Change %'] = df['Change %'].str.replace('%', '').astype(float)
print('B:')
print(df.head(5))

df=df[['Price']]
df.shape
df.head()

"""### 1-day prediction window (Hybrid)"""

# Scale the data using MinMaxScaler with range (0,1)
scaler = MinMaxScaler(feature_range=(0,1))
df = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)
df.head()

def fun(data, lag):
    """
    A function that takes in data and a lag value and returns two arrays: x and y.
    x is an array of shape (k, lag, n), where k is the number of samples and n is the number of features.
    y is an array of shape (k, 1), where k is the number of samples.
    Each sample in x is a sequence of lag consecutive observations from data, and the corresponding value in y is the next observation.
    """
    k = len(data) - lag
    x = []
    y = []
    for i in range(k):
        x.append(data[i:i+lag])
        y.append(data[i+lag,:1])
    x = np.array(x)
    y = np.array(y)
    return x, y

# Reverse the order of the data array
data = np.array(df.iloc[::-1])

# Set the number of data points to predict
prediction_window = 1

# Set the number of previous data points to use for prediction
lag = 30

# Split the data into train and test sets
test_start_index = len(data) - prediction_window - lag
test = data[test_start_index:]
train = data[:test_start_index]

# Use the function fun to create x_train, y_train, x_test, and y_test arrays
x_train, y_train = fun(train, lag)
x_test, y_test = fun(test, lag)

from tensorflow.keras.layers import GRU, LSTM, Dropout, Dense, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# Define the loss function
loss_fn = 'mse'

# Define the model
inputs = Input(shape=(30,1))
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.25)(gru)
gru = Dense(1, activation='relu')(gru)
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.25)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(1, activation='relu')(lstm)
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)
model = Model(inputs=inputs, outputs=outputs)

# Compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_fn, metrics=['mae','mse'])

# Fit the model with train data and validate with test data for 100 epochs
callback=EarlyStopping(min_delta=1e-5,patience=10)
history = model.fit(x_train, y_train, epochs=100, callbacks=[callback], validation_data=(x_test, y_test))

# Plot the MAE and MSE graphs
plt.plot(history.history['mae'], label='train')
plt.plot(history.history['val_mae'], label='test')
plt.title('Model MAE')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmae.pdf')
plt.show()

plt.plot(history.history['mse'], label='train')
plt.plot(history.history['val_mse'], label='test')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmse.pdf')
plt.show()

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# Define and fit the scaler object on the training data
# scaler = MinMaxScaler()
# scaler.fit(x_train)

# Predict on the test data and unscale the predicted and test data
y_pred_scaled = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred_scaled[::-1])
y_test_unscaled = scaler.inverse_transform(y_test)

# Print the evaluation metrics for the unscaled predictions
MAE_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE_unscaled = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('Unscaled Metrics')
print('MSE : ', MSE_unscaled)
print('RMSE : ', RMSE_unscaled)
print('MAE : ', MAE_unscaled)
print('MAPE : ', MAPE_unscaled)
print('R2 : ', R2_unscaled)

# Print the evaluation metrics for the scaled predictions
y_pred_scaled = y_pred_scaled.flatten()[::-1]
y_test_scaled = y_test.flatten()
MAE_scaled = mean_absolute_error(y_test_scaled, y_pred_scaled)
RMSE_scaled = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
R2_scaled = r2_score(y_test_scaled, y_pred_scaled)
MAPE_scaled = np.mean(np.abs((y_test_scaled - y_pred_scaled) / y_test_scaled)) * 100
MSE_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)

print('Scaled Metrics')
print('MSE : ', MSE_scaled)
print('RMSE : ', RMSE_scaled)
print('MAE : ', MAE_scaled)
print('MAPE : ', MAPE_scaled)
print('R2 : ', R2_scaled)

print('y_test_unscaled:')
print(y_test_unscaled)

print('y_pred_unscaled:')
print(y_pred_unscaled)

# Plot the actual vs predicted values for the unscaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_unscaled, 'go-', label='Actual')
plt.plot(y_pred_unscaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Unscaled)')
plt.legend()
plt.savefig('ActualPredictedValuesUnscaled.pdf')
plt.show()

# Plot the actual vs predicted values for the scaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_scaled, 'go-', label='Actual')
plt.plot(y_pred_scaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Scaled)')
plt.legend()
plt.savefig('ActualPredictedValuesScaled.pdf')
plt.show()

"""### 1-day prediction window (LSTM)"""

# Scale the data using MinMaxScaler with range (0,1)
scaler = MinMaxScaler(feature_range=(0,1))
df = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)
df.head()

def fun(data, lag):
    """
    A function that takes in data and a lag value and returns two arrays: x and y.
    x is an array of shape (k, lag, n), where k is the number of samples and n is the number of features.
    y is an array of shape (k, 1), where k is the number of samples.
    Each sample in x is a sequence of lag consecutive observations from data, and the corresponding value in y is the next observation.
    """
    k = len(data) - lag
    x = []
    y = []
    for i in range(k):
        x.append(data[i:i+lag])
        y.append(data[i+lag,:1])
    x = np.array(x)
    y = np.array(y)
    return x, y

# Reverse the order of the data array
data = np.array(df.iloc[::-1])

# Set the number of data points to predict
prediction_window = 1

# Set the number of previous data points to use for prediction
lag = 30

# Split the data into train and test sets
test_start_index = len(data) - prediction_window - lag
test = data[test_start_index:]
train = data[:test_start_index]

# Use the function fun to create x_train, y_train, x_test, and y_test arrays
x_train, y_train = fun(train, lag)
x_test, y_test = fun(test, lag)

from tensorflow.keras.layers import GRU, LSTM, Dropout, Dense, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# Define the loss function
loss_fn = 'mse'

# Define the model
inputs = Input(shape=(30,1))

# LSTM Network
lstm = LSTM(50, activation='relu')(inputs)
outputs = Dense(1)(lstm)

model = Model(inputs=inputs, outputs=outputs)
# Compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_fn, metrics=['mae','mse'])

# Fit the model with train data and validate with test data for 100 epochs
callback=EarlyStopping(min_delta=1e-5,patience=10)
history = model.fit(x_train, y_train, epochs=100, callbacks=[callback], validation_data=(x_test, y_test))

# Plot the MAE and MSE graphs
plt.plot(history.history['mae'], label='train')
plt.plot(history.history['val_mae'], label='test')
plt.title('Model MAE')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmae.pdf')
plt.show()

plt.plot(history.history['mse'], label='train')
plt.plot(history.history['val_mse'], label='test')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmse.pdf')
plt.show()

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# Define and fit the scaler object on the training data
# scaler = MinMaxScaler()
# scaler.fit(x_train)

# Predict on the test data and unscale the predicted and test data
y_pred_scaled = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred_scaled[::-1])
y_test_unscaled = scaler.inverse_transform(y_test.reshape(-1, 1))

# Print the evaluation metrics for the unscaled predictions
MAE_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE_unscaled = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('Unscaled Metrics')
print('MSE : ', MSE_unscaled)
print('RMSE : ', RMSE_unscaled)
print('MAE : ', MAE_unscaled)
print('MAPE : ', MAPE_unscaled)
print('R2 : ', R2_unscaled)

# Print the evaluation metrics for the scaled predictions
y_pred_scaled = y_pred_scaled.flatten()[::-1]
y_test_scaled = y_test.flatten()
MAE_scaled = mean_absolute_error(y_test_scaled, y_pred_scaled)
RMSE_scaled = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
R2_scaled = r2_score(y_test_scaled, y_pred_scaled)
MAPE_scaled = np.mean(np.abs((y_test_scaled - y_pred_scaled) / y_test_scaled)) * 100
MSE_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)

print('Scaled Metrics')
print('MSE : ', MSE_scaled)
print('RMSE : ', RMSE_scaled)
print('MAE : ', MAE_scaled)
print('MAPE : ', MAPE_scaled)
print('R2 : ', R2_scaled)

print('y_test_unscaled:')
print(y_test_unscaled)

print('y_pred_unscaled:')
print(y_pred_unscaled)

# Plot the actual vs predicted values for the unscaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_unscaled, 'go-', label='Actual')
plt.plot(y_pred_unscaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Unscaled)')
plt.legend()
plt.savefig('ActualPredictedValuesUnscaled.pdf')
plt.show()

# Plot the actual vs predicted values for the scaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_scaled, 'go-', label='Actual')
plt.plot(y_pred_scaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Scaled)')
plt.legend()
plt.savefig('ActualPredictedValuesScaled.pdf')
plt.show()

"""### 3-day prediction window (Hybrid)"""

# Scale the data using MinMaxScaler with range (0,1)
scaler = MinMaxScaler(feature_range=(0,1))
df = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)
df.head()

def fun(data, lag):
    """
    A function that takes in data and a lag value and returns two arrays: x and y.
    x is an array of shape (k, lag, n), where k is the number of samples and n is the number of features.
    y is an array of shape (k, 1), where k is the number of samples.
    Each sample in x is a sequence of lag consecutive observations from data, and the corresponding value in y is the next observation.
    """
    k = len(data) - lag
    x = []
    y = []
    for i in range(k):
        x.append(data[i:i+lag])
        y.append(data[i+lag,:1])
    x = np.array(x)
    y = np.array(y)
    return x, y

# Reverse the order of the data array
data = np.array(df.iloc[::-1])

# Set the number of data points to predict
prediction_window = 3

# Set the number of previous data points to use for prediction
lag = 30

# Split the data into train and test sets
test_start_index = len(data) - prediction_window - lag
test = data[test_start_index:]
train = data[:test_start_index]

# Use the function fun to create x_train, y_train, x_test, and y_test arrays
x_train, y_train = fun(train, lag)
x_test, y_test = fun(test, lag)

from tensorflow.keras.layers import GRU, LSTM, Dropout, Dense, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# Define the loss function
loss_fn = 'mse'

# Define the model
inputs = Input(shape=(30,1))
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.25)(gru)
gru = Dense(1, activation='relu')(gru)
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.25)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(1, activation='relu')(lstm)
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)
model = Model(inputs=inputs, outputs=outputs)

# Compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_fn, metrics=['mae','mse'])

# Fit the model with train data and validate with test data for 100 epochs
callback=EarlyStopping(min_delta=1e-5,patience=25)
history = model.fit(x_train, y_train, epochs=100, callbacks=[callback], validation_data=(x_test, y_test))

# Plot the MAE and MSE graphs
plt.plot(history.history['mae'], label='train')
plt.plot(history.history['val_mae'], label='test')
plt.title('Model MAE')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmae.pdf')
plt.show()

plt.plot(history.history['mse'], label='train')
plt.plot(history.history['val_mse'], label='test')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmse.pdf')
plt.show()

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# Define and fit the scaler object on the training data
# scaler = MinMaxScaler()
# scaler.fit(x_train)

# Predict on the test data and unscale the predicted and test data
y_pred_scaled = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred_scaled[::-1])
y_test_unscaled = scaler.inverse_transform(y_test)

# Print the evaluation metrics for the unscaled predictions
MAE_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE_unscaled = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('Unscaled Metrics')
print('MSE : ', MSE_unscaled)
print('RMSE : ', RMSE_unscaled)
print('MAE : ', MAE_unscaled)
print('MAPE : ', MAPE_unscaled)
print('R2 : ', R2_unscaled)

# Print the evaluation metrics for the scaled predictions
y_pred_scaled = y_pred_scaled.flatten()[::-1]
y_test_scaled = y_test.flatten()
MAE_scaled = mean_absolute_error(y_test_scaled, y_pred_scaled)
RMSE_scaled = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
R2_scaled = r2_score(y_test_scaled, y_pred_scaled)
MAPE_scaled = np.mean(np.abs((y_test_scaled - y_pred_scaled) / y_test_scaled)) * 100
MSE_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)

print('Scaled Metrics')
print('MSE : ', MSE_scaled)
print('RMSE : ', RMSE_scaled)
print('MAE : ', MAE_scaled)
print('MAPE : ', MAPE_scaled)
print('R2 : ', R2_scaled)

print('y_test_unscaled:')
print(y_test_unscaled)

print('y_pred_unscaled:')
print(y_pred_unscaled)

# Plot the actual vs predicted values for the unscaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_unscaled, 'go-', label='Actual')
plt.plot(y_pred_unscaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Unscaled)')
plt.legend()
plt.savefig('ActualPredictedValuesUnscaled.pdf')
plt.show()

# Plot the actual vs predicted values for the scaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_scaled, 'go-', label='Actual')
plt.plot(y_pred_scaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Scaled)')
plt.legend()
plt.savefig('ActualPredictedValuesScaled.pdf')
plt.show()

"""### 3-day prediction window (LSTM)"""

# Scale the data using MinMaxScaler with range (0,1)
scaler = MinMaxScaler(feature_range=(0,1))
df = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)
df.head()

def fun(data, lag):
    """
    A function that takes in data and a lag value and returns two arrays: x and y.
    x is an array of shape (k, lag, n), where k is the number of samples and n is the number of features.
    y is an array of shape (k, 1), where k is the number of samples.
    Each sample in x is a sequence of lag consecutive observations from data, and the corresponding value in y is the next observation.
    """
    k = len(data) - lag
    x = []
    y = []
    for i in range(k):
        x.append(data[i:i+lag])
        y.append(data[i+lag,:1])
    x = np.array(x)
    y = np.array(y)
    return x, y

# Reverse the order of the data array
data = np.array(df.iloc[::-1])

# Set the number of data points to predict
prediction_window = 3

# Set the number of previous data points to use for prediction
lag = 30

# Split the data into train and test sets
test_start_index = len(data) - prediction_window - lag
test = data[test_start_index:]
train = data[:test_start_index]

# Use the function fun to create x_train, y_train, x_test, and y_test arrays
x_train, y_train = fun(train, lag)
x_test, y_test = fun(test, lag)

from tensorflow.keras.layers import GRU, LSTM, Dropout, Dense, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# Define the loss function
loss_fn = 'mse'

# Define the model
inputs = Input(shape=(30,1))

# LSTM Network
lstm = LSTM(50, activation='relu')(inputs)
outputs = Dense(1)(lstm)

model = Model(inputs=inputs, outputs=outputs)
# Compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_fn, metrics=['mae','mse'])

# Fit the model with train data and validate with test data for 100 epochs
callback=EarlyStopping(min_delta=1e-5,patience=25)
history = model.fit(x_train, y_train, epochs=100, callbacks=[callback], validation_data=(x_test, y_test))

# Plot the MAE and MSE graphs
plt.plot(history.history['mae'], label='train')
plt.plot(history.history['val_mae'], label='test')
plt.title('Model MAE')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmae.pdf')
plt.show()

plt.plot(history.history['mse'], label='train')
plt.plot(history.history['val_mse'], label='test')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmse.pdf')
plt.show()

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# Define and fit the scaler object on the training data
# scaler = MinMaxScaler()
# scaler.fit(x_train)

# Predict on the test data and unscale the predicted and test data
y_pred_scaled = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred_scaled[::-1])
y_test_unscaled = scaler.inverse_transform(y_test.reshape(-1, 1))

# Print the evaluation metrics for the unscaled predictions
MAE_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE_unscaled = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('Unscaled Metrics')
print('MSE : ', MSE_unscaled)
print('RMSE : ', RMSE_unscaled)
print('MAE : ', MAE_unscaled)
print('MAPE : ', MAPE_unscaled)
print('R2 : ', R2_unscaled)

# Print the evaluation metrics for the scaled predictions
y_pred_scaled = y_pred_scaled.flatten()[::-1]
y_test_scaled = y_test.flatten()
MAE_scaled = mean_absolute_error(y_test_scaled, y_pred_scaled)
RMSE_scaled = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
R2_scaled = r2_score(y_test_scaled, y_pred_scaled)
MAPE_scaled = np.mean(np.abs((y_test_scaled - y_pred_scaled) / y_test_scaled)) * 100
MSE_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)

print('Scaled Metrics')
print('MSE : ', MSE_scaled)
print('RMSE : ', RMSE_scaled)
print('MAE : ', MAE_scaled)
print('MAPE : ', MAPE_scaled)
print('R2 : ', R2_scaled)

print('y_test_unscaled:')
print(y_test_unscaled)

print('y_pred_unscaled:')
print(y_pred_unscaled)

# Plot the actual vs predicted values for the unscaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_unscaled, 'go-', label='Actual')
plt.plot(y_pred_unscaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Unscaled)')
plt.legend()
plt.savefig('ActualPredictedValuesUnscaled.pdf')
plt.show()

# Plot the actual vs predicted values for the scaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_scaled, 'go-', label='Actual')
plt.plot(y_pred_scaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Scaled)')
plt.legend()
plt.savefig('ActualPredictedValuesScaled.pdf')
plt.show()

"""### 7-day prediction window (Hybrid)"""

# Scale the data using MinMaxScaler with range (0,1)
scaler = MinMaxScaler(feature_range=(0,1))
df = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)
df.head()

def fun(data, lag):
    """
    A function that takes in data and a lag value and returns two arrays: x and y.
    x is an array of shape (k, lag, n), where k is the number of samples and n is the number of features.
    y is an array of shape (k, 1), where k is the number of samples.
    Each sample in x is a sequence of lag consecutive observations from data, and the corresponding value in y is the next observation.
    """
    k = len(data) - lag
    x = []
    y = []
    for i in range(k):
        x.append(data[i:i+lag])
        y.append(data[i+lag,:1])
    x = np.array(x)
    y = np.array(y)
    return x, y

# Reverse the order of the data array
data = np.array(df.iloc[::-1])

# Set the number of data points to predict
prediction_window = 7

# Set the number of previous data points to use for prediction
lag = 30

# Split the data into train and test sets
test_start_index = len(data) - prediction_window - lag
test = data[test_start_index:]
train = data[:test_start_index]

# Use the function fun to create x_train, y_train, x_test, and y_test arrays
x_train, y_train = fun(train, lag)
x_test, y_test = fun(test, lag)

from tensorflow.keras.layers import GRU, LSTM, Dropout, Dense, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# Define the loss function
loss_fn = 'mse'

# Define the model
inputs = Input(shape=(30,1))
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.25)(gru)
gru = Dense(1, activation='relu')(gru)
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.25)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(1, activation='relu')(lstm)
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)
model = Model(inputs=inputs, outputs=outputs)

# Compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_fn, metrics=['mae','mse'])

# Fit the model with train data and validate with test data for 100 epochs
callback=EarlyStopping(min_delta=1e-5,patience=25)
history = model.fit(x_train, y_train, epochs=100, callbacks=[callback], validation_data=(x_test, y_test))

# Plot the MAE and MSE graphs
plt.plot(history.history['mae'], label='train')
plt.plot(history.history['val_mae'], label='test')
plt.title('Model MAE')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmae.pdf')
plt.show()

plt.plot(history.history['mse'], label='train')
plt.plot(history.history['val_mse'], label='test')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmse.pdf')
plt.show()

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# Define and fit the scaler object on the training data
# scaler = MinMaxScaler()
# scaler.fit(x_train)

# Predict on the test data and unscale the predicted and test data
y_pred_scaled = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred_scaled[::-1])
y_test_unscaled = scaler.inverse_transform(y_test)

# Print the evaluation metrics for the unscaled predictions
MAE_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE_unscaled = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('Unscaled Metrics')
print('MSE : ', MSE_unscaled)
print('RMSE : ', RMSE_unscaled)
print('MAE : ', MAE_unscaled)
print('MAPE : ', MAPE_unscaled)
print('R2 : ', R2_unscaled)

# Print the evaluation metrics for the scaled predictions
y_pred_scaled = y_pred_scaled.flatten()[::-1]
y_test_scaled = y_test.flatten()
MAE_scaled = mean_absolute_error(y_test_scaled, y_pred_scaled)
RMSE_scaled = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
R2_scaled = r2_score(y_test_scaled, y_pred_scaled)
MAPE_scaled = np.mean(np.abs((y_test_scaled - y_pred_scaled) / y_test_scaled)) * 100
MSE_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)

print('Scaled Metrics')
print('MSE : ', MSE_scaled)
print('RMSE : ', RMSE_scaled)
print('MAE : ', MAE_scaled)
print('MAPE : ', MAPE_scaled)
print('R2 : ', R2_scaled)

print('y_test_unscaled:')
print(y_test_unscaled)

print('y_pred_unscaled:')
print(y_pred_unscaled)

# Plot the actual vs predicted values for the unscaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_unscaled, 'go-', label='Actual')
plt.plot(y_pred_unscaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Unscaled)')
plt.legend()
plt.savefig('ActualPredictedValuesUnscaled.pdf')
plt.show()

# Plot the actual vs predicted values for the scaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_scaled, 'go-', label='Actual')
plt.plot(y_pred_scaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Scaled)')
plt.legend()
plt.savefig('ActualPredictedValuesScaled.pdf')
plt.show()

"""### 7-day prediction window (LSTM)"""

# Scale the data using MinMaxScaler with range (0,1)
scaler = MinMaxScaler(feature_range=(0,1))
df = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)
df.head()

def fun(data, lag):
    """
    A function that takes in data and a lag value and returns two arrays: x and y.
    x is an array of shape (k, lag, n), where k is the number of samples and n is the number of features.
    y is an array of shape (k, 1), where k is the number of samples.
    Each sample in x is a sequence of lag consecutive observations from data, and the corresponding value in y is the next observation.
    """
    k = len(data) - lag
    x = []
    y = []
    for i in range(k):
        x.append(data[i:i+lag])
        y.append(data[i+lag,:1])
    x = np.array(x)
    y = np.array(y)
    return x, y

# Reverse the order of the data array
data = np.array(df.iloc[::-1])

# Set the number of data points to predict
prediction_window = 7

# Set the number of previous data points to use for prediction
lag = 30

# Split the data into train and test sets
test_start_index = len(data) - prediction_window - lag
test = data[test_start_index:]
train = data[:test_start_index]

# Use the function fun to create x_train, y_train, x_test, and y_test arrays
x_train, y_train = fun(train, lag)
x_test, y_test = fun(test, lag)

from tensorflow.keras.layers import GRU, LSTM, Dropout, Dense, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# Define the loss function
loss_fn = 'mse'

# Define the model
inputs = Input(shape=(30,1))

# LSTM Network
lstm = LSTM(50, activation='relu')(inputs)
outputs = Dense(1)(lstm)

model = Model(inputs=inputs, outputs=outputs)
# Compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_fn, metrics=['mae','mse'])

# Fit the model with train data and validate with test data for 100 epochs
callback=EarlyStopping(min_delta=1e-5,patience=2)
history = model.fit(x_train, y_train, epochs=100, callbacks=[callback], validation_data=(x_test, y_test))

# Plot the MAE and MSE graphs
plt.plot(history.history['mae'], label='train')
plt.plot(history.history['val_mae'], label='test')
plt.title('Model MAE')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmae.pdf')
plt.show()

plt.plot(history.history['mse'], label='train')
plt.plot(history.history['val_mse'], label='test')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmse.pdf')
plt.show()

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# Define and fit the scaler object on the training data
# scaler = MinMaxScaler()
# scaler.fit(x_train)

# Predict on the test data and unscale the predicted and test data
y_pred_scaled = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred_scaled[::-1])
y_test_unscaled = scaler.inverse_transform(y_test.reshape(-1, 1))

# Print the evaluation metrics for the unscaled predictions
MAE_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE_unscaled = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('Unscaled Metrics')
print('MSE : ', MSE_unscaled)
print('RMSE : ', RMSE_unscaled)
print('MAE : ', MAE_unscaled)
print('MAPE : ', MAPE_unscaled)
print('R2 : ', R2_unscaled)

# Print the evaluation metrics for the scaled predictions
y_pred_scaled = y_pred_scaled.flatten()[::-1]
y_test_scaled = y_test.flatten()
MAE_scaled = mean_absolute_error(y_test_scaled, y_pred_scaled)
RMSE_scaled = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
R2_scaled = r2_score(y_test_scaled, y_pred_scaled)
MAPE_scaled = np.mean(np.abs((y_test_scaled - y_pred_scaled) / y_test_scaled)) * 100
MSE_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)

print('Scaled Metrics')
print('MSE : ', MSE_scaled)
print('RMSE : ', RMSE_scaled)
print('MAE : ', MAE_scaled)
print('MAPE : ', MAPE_scaled)
print('R2 : ', R2_scaled)

print('y_test_unscaled:')
print(y_test_unscaled)

print('y_pred_unscaled:')
print(y_pred_unscaled)

# Plot the actual vs predicted values for the unscaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_unscaled, 'go-', label='Actual')
plt.plot(y_pred_unscaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Unscaled)')
plt.legend()
plt.savefig('ActualPredictedValuesUnscaled.pdf')
plt.show()

# Plot the actual vs predicted values for the scaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_scaled, 'go-', label='Actual')
plt.plot(y_pred_scaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Scaled)')
plt.legend()
plt.savefig('ActualPredictedValuesScaled.pdf')
plt.show()

"""## Monero"""

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from tensorflow.keras.models import Sequential
from keras.layers import Dense, Conv1D, MaxPooling1D , Dropout , Flatten , BatchNormalization,LSTM
from tensorflow.keras.optimizers import SGD,Adam
from sklearn.metrics import confusion_matrix
import pandas as pd 
from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
import warnings
warnings.filterwarnings('ignore')

# Load the data from the csv file
df = pd.read_csv('/content/Monero.csv')

# Print the first two rows
print('A:')
print(df.head(5))

df=df[['Price']]
df.shape
df.head()

"""### 1-day prediction window (Hybrid)"""

# Scale the data using MinMaxScaler with range (0,1)
scaler = MinMaxScaler(feature_range=(0,1))
df = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)
df.head()

def fun(data, lag):
    """
    A function that takes in data and a lag value and returns two arrays: x and y.
    x is an array of shape (k, lag, n), where k is the number of samples and n is the number of features.
    y is an array of shape (k, 1), where k is the number of samples.
    Each sample in x is a sequence of lag consecutive observations from data, and the corresponding value in y is the next observation.
    """
    k = len(data) - lag
    x = []
    y = []
    for i in range(k):
        x.append(data[i:i+lag])
        y.append(data[i+lag,:1])
    x = np.array(x)
    y = np.array(y)
    return x, y

# Reverse the order of the data array
data = np.array(df.iloc[::-1])

# Set the number of data points to predict
prediction_window = 1

# Set the number of previous data points to use for prediction
lag = 30

# Split the data into train and test sets
test_start_index = len(data) - prediction_window - lag
test = data[test_start_index:]
train = data[:test_start_index]

# Use the function fun to create x_train, y_train, x_test, and y_test arrays
x_train, y_train = fun(train, lag)
x_test, y_test = fun(test, lag)

from tensorflow.keras.layers import GRU, LSTM, Dropout, Dense, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# Define the loss function
loss_fn = 'mse'

# Define the model
inputs = Input(shape=(30,1))
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.25)(gru)
gru = Dense(1, activation='relu')(gru)
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.25)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(1, activation='relu')(lstm)
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)
model = Model(inputs=inputs, outputs=outputs)

# Compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_fn, metrics=['mae','mse'])

# Fit the model with train data and validate with test data for 100 epochs
callback=EarlyStopping(min_delta=1e-5,patience=25)
history = model.fit(x_train, y_train, epochs=100, callbacks=[callback], validation_data=(x_test, y_test))

# Plot the MAE and MSE graphs
plt.plot(history.history['mae'], label='train')
plt.plot(history.history['val_mae'], label='test')
plt.title('Model MAE')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmaeM.pdf')
plt.show()

plt.plot(history.history['mse'], label='train')
plt.plot(history.history['val_mse'], label='test')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmseM.pdf')
plt.show()

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# Define and fit the scaler object on the training data
# scaler = MinMaxScaler()
# scaler.fit(x_train)

# Predict on the test data and unscale the predicted and test data
y_pred_scaled = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred_scaled[::-1])
y_test_unscaled = scaler.inverse_transform(y_test)

# Print the evaluation metrics for the unscaled predictions
MAE_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE_unscaled = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('Unscaled Metrics')
print('MSE : ', MSE_unscaled)
print('RMSE : ', RMSE_unscaled)
print('MAE : ', MAE_unscaled)
print('MAPE : ', MAPE_unscaled)
print('R2 : ', R2_unscaled)

# Print the evaluation metrics for the scaled predictions
y_pred_scaled = y_pred_scaled.flatten()[::-1]
y_test_scaled = y_test.flatten()
MAE_scaled = mean_absolute_error(y_test_scaled, y_pred_scaled)
RMSE_scaled = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
R2_scaled = r2_score(y_test_scaled, y_pred_scaled)
MAPE_scaled = np.mean(np.abs((y_test_scaled - y_pred_scaled) / y_test_scaled)) * 100
MSE_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)

print('Scaled Metrics')
print('MSE : ', MSE_scaled)
print('RMSE : ', RMSE_scaled)
print('MAE : ', MAE_scaled)
print('MAPE : ', MAPE_scaled)
print('R2 : ', R2_scaled)

print('y_test_unscaled:')
print(y_test_unscaled)

print('y_pred_unscaled:')
print(y_pred_unscaled)


# Plot the actual vs predicted values for the unscaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_unscaled, 'go-', label='Actual')
plt.plot(y_pred_unscaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Unscaled)')
plt.legend()
plt.savefig('ActualPredictedValuesUnscaledM.pdf')
plt.show()

# Plot the actual vs predicted values for the scaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_scaled, 'go-', label='Actual')
plt.plot(y_pred_scaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Scaled)')
plt.legend()
plt.savefig('ActualPredictedValuesScaledM.pdf')
plt.show()

"""### 1-day prediction window (LSTM)"""

# Scale the data using MinMaxScaler with range (0,1)
scaler = MinMaxScaler(feature_range=(0,1))
df = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)
df.head()

def fun(data, lag):
    """
    A function that takes in data and a lag value and returns two arrays: x and y.
    x is an array of shape (k, lag, n), where k is the number of samples and n is the number of features.
    y is an array of shape (k, 1), where k is the number of samples.
    Each sample in x is a sequence of lag consecutive observations from data, and the corresponding value in y is the next observation.
    """
    k = len(data) - lag
    x = []
    y = []
    for i in range(k):
        x.append(data[i:i+lag])
        y.append(data[i+lag,:1])
    x = np.array(x)
    y = np.array(y)
    return x, y

# Reverse the order of the data array
data = np.array(df.iloc[::-1])

# Set the number of data points to predict
prediction_window = 1

# Set the number of previous data points to use for prediction
lag = 30

# Split the data into train and test sets
test_start_index = len(data) - prediction_window - lag
test = data[test_start_index:]
train = data[:test_start_index]

# Use the function fun to create x_train, y_train, x_test, and y_test arrays
x_train, y_train = fun(train, lag)
x_test, y_test = fun(test, lag)

from tensorflow.keras.layers import GRU, LSTM, Dropout, Dense, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# Define the loss function
loss_fn = 'mse'

# Define the model
inputs = Input(shape=(30,1))

# LSTM Network
lstm = LSTM(50, activation='relu')(inputs)
outputs = Dense(1)(lstm)

model = Model(inputs=inputs, outputs=outputs)
# Compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_fn, metrics=['mae','mse'])

# Fit the model with train data and validate with test data for 100 epochs
callback=EarlyStopping(min_delta=1e-5,patience=2)
history = model.fit(x_train, y_train, epochs=1, callbacks=[callback], validation_data=(x_test, y_test))

# Plot the MAE and MSE graphs
plt.plot(history.history['mae'], label='train')
plt.plot(history.history['val_mae'], label='test')
plt.title('Model MAE')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmaeM.pdf')
plt.show()

plt.plot(history.history['mse'], label='train')
plt.plot(history.history['val_mse'], label='test')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmseM.pdf')
plt.show()

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# Define and fit the scaler object on the training data
# scaler = MinMaxScaler()
# scaler.fit(x_train)

# Predict on the test data and unscale the predicted and test data
y_pred_scaled = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred_scaled[::-1])
y_test_unscaled = scaler.inverse_transform(y_test)

# Print the evaluation metrics for the unscaled predictions
MAE_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE_unscaled = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('Unscaled Metrics')
print('MSE : ', MSE_unscaled)
print('RMSE : ', RMSE_unscaled)
print('MAE : ', MAE_unscaled)
print('MAPE : ', MAPE_unscaled)
print('R2 : ', R2_unscaled)

# Print the evaluation metrics for the scaled predictions
y_pred_scaled = y_pred_scaled.flatten()[::-1]
y_test_scaled = y_test.flatten()
MAE_scaled = mean_absolute_error(y_test_scaled, y_pred_scaled)
RMSE_scaled = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
R2_scaled = r2_score(y_test_scaled, y_pred_scaled)
MAPE_scaled = np.mean(np.abs((y_test_scaled - y_pred_scaled) / y_test_scaled)) * 100
MSE_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)

print('Scaled Metrics')
print('MSE : ', MSE_scaled)
print('RMSE : ', RMSE_scaled)
print('MAE : ', MAE_scaled)
print('MAPE : ', MAPE_scaled)
print('R2 : ', R2_scaled)

print('y_test_unscaled:')
print(y_test_unscaled)

print('y_pred_unscaled:')
print(y_pred_unscaled)


# Plot the actual vs predicted values for the unscaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_unscaled, 'go-', label='Actual')
plt.plot(y_pred_unscaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Unscaled)')
plt.legend()
plt.savefig('ActualPredictedValuesUnscaledM.pdf')
plt.show()

# Plot the actual vs predicted values for the scaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_scaled, 'go-', label='Actual')
plt.plot(y_pred_scaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Scaled)')
plt.legend()
plt.savefig('ActualPredictedValuesScaledM.pdf')
plt.show()

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# Define and fit the scaler object on the training data
# scaler = MinMaxScaler()
# scaler.fit(x_train)

# Predict on the test data and unscale the predicted and test data
y_pred_scaled = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred_scaled[::-1])
y_test_unscaled = scaler.inverse_transform(y_test)

# Print the evaluation metrics for the unscaled predictions
MAE_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE_unscaled = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('Unscaled Metrics')
print('MSE : ', MSE_unscaled)
print('RMSE : ', RMSE_unscaled)
print('MAE : ', MAE_unscaled)
print('MAPE : ', MAPE_unscaled)
print('R2 : ', R2_unscaled)

# Print the evaluation metrics for the scaled predictions
y_pred_scaled = y_pred_scaled.flatten()[::-1]
y_test_scaled = y_test.flatten()
MAE_scaled = mean_absolute_error(y_test_scaled, y_pred_scaled)
RMSE_scaled = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
R2_scaled = r2_score(y_test_scaled, y_pred_scaled)
MAPE_scaled = np.mean(np.abs((y_test_scaled - y_pred_scaled) / y_test_scaled)) * 100
MSE_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)

print('Scaled Metrics')
print('MSE : ', MSE_scaled)
print('RMSE : ', RMSE_scaled)
print('MAE : ', MAE_scaled)
print('MAPE : ', MAPE_scaled)
print('R2 : ', R2_scaled)

print('y_test_unscaled:')
print(y_test_unscaled)

print('y_pred_unscaled:')
print(y_pred_unscaled)


# Plot the actual vs predicted values for the unscaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_unscaled, 'go-', label='Actual')
plt.plot(y_pred_unscaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Unscaled)')
plt.legend()
plt.savefig('ActualPredictedValuesUnscaledM.pdf')
plt.show()

# Plot the actual vs predicted values for the scaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_scaled, 'go-', label='Actual')
plt.plot(y_pred_scaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Scaled)')
plt.legend()
plt.savefig('ActualPredictedValuesScaledM.pdf')
plt.show()

"""### 3-day prediction window (Hybrid)"""

# Scale the data using MinMaxScaler with range (0,1)
scaler = MinMaxScaler(feature_range=(0,1))
df = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)
df.head()

def fun(data, lag):
    """
    A function that takes in data and a lag value and returns two arrays: x and y.
    x is an array of shape (k, lag, n), where k is the number of samples and n is the number of features.
    y is an array of shape (k, 1), where k is the number of samples.
    Each sample in x is a sequence of lag consecutive observations from data, and the corresponding value in y is the next observation.
    """
    k = len(data) - lag
    x = []
    y = []
    for i in range(k):
        x.append(data[i:i+lag])
        y.append(data[i+lag,:1])
    x = np.array(x)
    y = np.array(y)
    return x, y

# Reverse the order of the data array
data = np.array(df.iloc[::-1])

# Set the number of data points to predict
prediction_window = 3

# Set the number of previous data points to use for prediction
lag = 30

# Split the data into train and test sets
test_start_index = len(data) - prediction_window - lag
test = data[test_start_index:]
train = data[:test_start_index]

# Use the function fun to create x_train, y_train, x_test, and y_test arrays
x_train, y_train = fun(train, lag)
x_test, y_test = fun(test, lag)

from tensorflow.keras.layers import GRU, LSTM, Dropout, Dense, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# Define the loss function
loss_fn = 'mse'

# Define the model
inputs = Input(shape=(30,1))
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.25)(gru)
gru = Dense(1, activation='relu')(gru)
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.25)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(1, activation='relu')(lstm)
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)
model = Model(inputs=inputs, outputs=outputs)

# Compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_fn, metrics=['mae','mse'])

# Fit the model with train data and validate with test data for 100 epochs
callback=EarlyStopping(min_delta=1e-5,patience=25)
history = model.fit(x_train, y_train, epochs=100, callbacks=[callback], validation_data=(x_test, y_test))

# Plot the MAE and MSE graphs
plt.plot(history.history['mae'], label='train')
plt.plot(history.history['val_mae'], label='test')
plt.title('Model MAE')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmaeM.pdf')
plt.show()

plt.plot(history.history['mse'], label='train')
plt.plot(history.history['val_mse'], label='test')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmseM.pdf')
plt.show()

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# Define and fit the scaler object on the training data
# scaler = MinMaxScaler()
# scaler.fit(x_train)

# Predict on the test data and unscale the predicted and test data
y_pred_scaled = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred_scaled[::-1])
y_test_unscaled = scaler.inverse_transform(y_test)

# Print the evaluation metrics for the unscaled predictions
MAE_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE_unscaled = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('Unscaled Metrics')
print('MSE : ', MSE_unscaled)
print('RMSE : ', RMSE_unscaled)
print('MAE : ', MAE_unscaled)
print('MAPE : ', MAPE_unscaled)
print('R2 : ', R2_unscaled)

# Print the evaluation metrics for the scaled predictions
y_pred_scaled = y_pred_scaled.flatten()[::-1]
y_test_scaled = y_test.flatten()
MAE_scaled = mean_absolute_error(y_test_scaled, y_pred_scaled)
RMSE_scaled = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
R2_scaled = r2_score(y_test_scaled, y_pred_scaled)
MAPE_scaled = np.mean(np.abs((y_test_scaled - y_pred_scaled) / y_test_scaled)) * 100
MSE_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)

print('Scaled Metrics')
print('MSE : ', MSE_scaled)
print('RMSE : ', RMSE_scaled)
print('MAE : ', MAE_scaled)
print('MAPE : ', MAPE_scaled)
print('R2 : ', R2_scaled)

print('y_test_unscaled:')
print(y_test_unscaled)

print('y_pred_unscaled:')
print(y_pred_unscaled)


# Plot the actual vs predicted values for the unscaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_unscaled, 'go-', label='Actual')
plt.plot(y_pred_unscaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Unscaled)')
plt.legend()
plt.savefig('ActualPredictedValuesUnscaledM.pdf')
plt.show()

# Plot the actual vs predicted values for the scaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_scaled, 'go-', label='Actual')
plt.plot(y_pred_scaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Scaled)')
plt.legend()
plt.savefig('ActualPredictedValuesScaledM.pdf')
plt.show()

"""### 3-day prediction window (LSTM)"""

# Scale the data using MinMaxScaler with range (0,1)
scaler = MinMaxScaler(feature_range=(0,1))
df = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)
df.head()

def fun(data, lag):
    """
    A function that takes in data and a lag value and returns two arrays: x and y.
    x is an array of shape (k, lag, n), where k is the number of samples and n is the number of features.
    y is an array of shape (k, 1), where k is the number of samples.
    Each sample in x is a sequence of lag consecutive observations from data, and the corresponding value in y is the next observation.
    """
    k = len(data) - lag
    x = []
    y = []
    for i in range(k):
        x.append(data[i:i+lag])
        y.append(data[i+lag,:1])
    x = np.array(x)
    y = np.array(y)
    return x, y

# Reverse the order of the data array
data = np.array(df.iloc[::-1])

# Set the number of data points to predict
prediction_window = 3

# Set the number of previous data points to use for prediction
lag = 30

# Split the data into train and test sets
test_start_index = len(data) - prediction_window - lag
test = data[test_start_index:]
train = data[:test_start_index]

# Use the function fun to create x_train, y_train, x_test, and y_test arrays
x_train, y_train = fun(train, lag)
x_test, y_test = fun(test, lag)

from tensorflow.keras.layers import GRU, LSTM, Dropout, Dense, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# Define the loss function
loss_fn = 'mse'

# Define the model
inputs = Input(shape=(30,1))

# LSTM Network
lstm = LSTM(50, activation='relu')(inputs)
outputs = Dense(1)(lstm)

model = Model(inputs=inputs, outputs=outputs)
# Compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_fn, metrics=['mae','mse'])

# Fit the model with train data and validate with test data for 100 epochs
callback=EarlyStopping(min_delta=1e-5,patience=20)
history = model.fit(x_train, y_train, epochs=2, callbacks=[callback], validation_data=(x_test, y_test))

# Plot the MAE and MSE graphs
plt.plot(history.history['mae'], label='train')
plt.plot(history.history['val_mae'], label='test')
plt.title('Model MAE')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmaeM.pdf')
plt.show()

plt.plot(history.history['mse'], label='train')
plt.plot(history.history['val_mse'], label='test')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmseM.pdf')
plt.show()

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# Define and fit the scaler object on the training data
# scaler = MinMaxScaler()
# scaler.fit(x_train)

# Predict on the test data and unscale the predicted and test data
y_pred_scaled = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred_scaled[::-1])
y_test_unscaled = scaler.inverse_transform(y_test)

# Print the evaluation metrics for the unscaled predictions
MAE_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE_unscaled = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('Unscaled Metrics')
print('MSE : ', MSE_unscaled)
print('RMSE : ', RMSE_unscaled)
print('MAE : ', MAE_unscaled)
print('MAPE : ', MAPE_unscaled)
print('R2 : ', R2_unscaled)

# Print the evaluation metrics for the scaled predictions
y_pred_scaled = y_pred_scaled.flatten()[::-1]
y_test_scaled = y_test.flatten()
MAE_scaled = mean_absolute_error(y_test_scaled, y_pred_scaled)
RMSE_scaled = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
R2_scaled = r2_score(y_test_scaled, y_pred_scaled)
MAPE_scaled = np.mean(np.abs((y_test_scaled - y_pred_scaled) / y_test_scaled)) * 100
MSE_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)

print('Scaled Metrics')
print('MSE : ', MSE_scaled)
print('RMSE : ', RMSE_scaled)
print('MAE : ', MAE_scaled)
print('MAPE : ', MAPE_scaled)
print('R2 : ', R2_scaled)

print('y_test_unscaled:')
print(y_test_unscaled)

print('y_pred_unscaled:')
print(y_pred_unscaled)


# Plot the actual vs predicted values for the unscaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_unscaled, 'go-', label='Actual')
plt.plot(y_pred_unscaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Unscaled)')
plt.legend()
plt.savefig('ActualPredictedValuesUnscaledM.pdf')
plt.show()

# Plot the actual vs predicted values for the scaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_scaled, 'go-', label='Actual')
plt.plot(y_pred_scaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Scaled)')
plt.legend()
plt.savefig('ActualPredictedValuesScaledM.pdf')
plt.show()

"""### 7-day prediction window (Hybrid)"""

# Scale the data using MinMaxScaler with range (0,1)
scaler = MinMaxScaler(feature_range=(0,1))
df = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)
df.head()

def fun(data, lag):
    """
    A function that takes in data and a lag value and returns two arrays: x and y.
    x is an array of shape (k, lag, n), where k is the number of samples and n is the number of features.
    y is an array of shape (k, 1), where k is the number of samples.
    Each sample in x is a sequence of lag consecutive observations from data, and the corresponding value in y is the next observation.
    """
    k = len(data) - lag
    x = []
    y = []
    for i in range(k):
        x.append(data[i:i+lag])
        y.append(data[i+lag,:1])
    x = np.array(x)
    y = np.array(y)
    return x, y

# Reverse the order of the data array
data = np.array(df.iloc[::-1])

# Set the number of data points to predict
prediction_window = 7

# Set the number of previous data points to use for prediction
lag = 30

# Split the data into train and test sets
test_start_index = len(data) - prediction_window - lag
test = data[test_start_index:]
train = data[:test_start_index]

# Use the function fun to create x_train, y_train, x_test, and y_test arrays
x_train, y_train = fun(train, lag)
x_test, y_test = fun(test, lag)

from tensorflow.keras.layers import GRU, LSTM, Dropout, Dense, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# Define the loss function
loss_fn = 'mse'

# Define the model
inputs = Input(shape=(30,1))
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.1)(gru)
gru = Dense(1, activation='relu')(gru)
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.1)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(1, activation='relu')(lstm)
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)
model = Model(inputs=inputs, outputs=outputs)

# # LSTM Network
# lstm = LSTM(50, activation='relu')(inputs)
# outputs = Dense(1)(lstm)

# Compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_fn, metrics=['mae','mse'])

# Fit the model with train data and validate with test data for 100 epochs
callback=EarlyStopping(min_delta=1e-5,patience=26)
history = model.fit(x_train, y_train, epochs=100, callbacks=[callback], validation_data=(x_test, y_test))

# Plot the MAE and MSE graphs
plt.plot(history.history['mae'], label='train')
plt.plot(history.history['val_mae'], label='test')
plt.title('Model MAE')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmaeM.pdf')
plt.show()

plt.plot(history.history['mse'], label='train')
plt.plot(history.history['val_mse'], label='test')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmseM.pdf')
plt.show()

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# Define and fit the scaler object on the training data
# scaler = MinMaxScaler()
# scaler.fit(x_train)

# Predict on the test data and unscale the predicted and test data
y_pred_scaled = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred_scaled[::-1])
y_test_unscaled = scaler.inverse_transform(y_test)

# Print the evaluation metrics for the unscaled predictions
MAE_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE_unscaled = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('Unscaled Metrics')
print('MSE : ', MSE_unscaled)
print('RMSE : ', RMSE_unscaled)
print('MAE : ', MAE_unscaled)
print('MAPE : ', MAPE_unscaled)
print('R2 : ', R2_unscaled)

# Print the evaluation metrics for the scaled predictions
y_pred_scaled = y_pred_scaled.flatten()[::-1]
y_test_scaled = y_test.flatten()
MAE_scaled = mean_absolute_error(y_test_scaled, y_pred_scaled)
RMSE_scaled = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
R2_scaled = r2_score(y_test_scaled, y_pred_scaled)
MAPE_scaled = np.mean(np.abs((y_test_scaled - y_pred_scaled) / y_test_scaled)) * 100
MSE_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)

print('Scaled Metrics')
print('MSE : ', MSE_scaled)
print('RMSE : ', RMSE_scaled)
print('MAE : ', MAE_scaled)
print('MAPE : ', MAPE_scaled)
print('R2 : ', R2_scaled)

print('y_test_unscaled:')
print(y_test_unscaled)

print('y_pred_unscaled:')
print(y_pred_unscaled)


# Plot the actual vs predicted values for the unscaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_unscaled, 'go-', label='Actual')
plt.plot(y_pred_unscaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Unscaled)')
plt.legend()
plt.savefig('ActualPredictedValuesUnscaledM.pdf')
plt.show()

# Plot the actual vs predicted values for the scaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_scaled, 'go-', label='Actual')
plt.plot(y_pred_scaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Scaled)')
plt.legend()
plt.savefig('ActualPredictedValuesScaledM.pdf')
plt.show()

"""### 7-day prediction window (LSTM)"""

# Scale the data using MinMaxScaler with range (0,1)
scaler = MinMaxScaler(feature_range=(0,1))
df = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)
df.head()

def fun(data, lag):
    """
    A function that takes in data and a lag value and returns two arrays: x and y.
    x is an array of shape (k, lag, n), where k is the number of samples and n is the number of features.
    y is an array of shape (k, 1), where k is the number of samples.
    Each sample in x is a sequence of lag consecutive observations from data, and the corresponding value in y is the next observation.
    """
    k = len(data) - lag
    x = []
    y = []
    for i in range(k):
        x.append(data[i:i+lag])
        y.append(data[i+lag,:1])
    x = np.array(x)
    y = np.array(y)
    return x, y

# Reverse the order of the data array
data = np.array(df.iloc[::-1])

# Set the number of data points to predict
prediction_window = 7

# Set the number of previous data points to use for prediction
lag = 30

# Split the data into train and test sets
test_start_index = len(data) - prediction_window - lag
test = data[test_start_index:]
train = data[:test_start_index]

# Use the function fun to create x_train, y_train, x_test, and y_test arrays
x_train, y_train = fun(train, lag)
x_test, y_test = fun(test, lag)

from tensorflow.keras.layers import GRU, LSTM, Dropout, Dense, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# Define the loss function
loss_fn = 'mse'

# Define the model
inputs = Input(shape=(30,1))

# LSTM Network
lstm = LSTM(50, activation='relu')(inputs)
outputs = Dense(1)(lstm)

model = Model(inputs=inputs, outputs=outputs)
# Compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_fn, metrics=['mae','mse'])

# Fit the model with train data and validate with test data for 100 epochs
callback=EarlyStopping(min_delta=1e-5,patience=20)
history = model.fit(x_train, y_train, epochs=1, callbacks=[callback], validation_data=(x_test, y_test))

# Plot the MAE and MSE graphs
plt.plot(history.history['mae'], label='train')
plt.plot(history.history['val_mae'], label='test')
plt.title('Model MAE')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmaeM.pdf')
plt.show()

plt.plot(history.history['mse'], label='train')
plt.plot(history.history['val_mse'], label='test')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmseM.pdf')
plt.show()

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# Define and fit the scaler object on the training data
# scaler = MinMaxScaler()
# scaler.fit(x_train)

# Predict on the test data and unscale the predicted and test data
y_pred_scaled = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred_scaled[::-1])
y_test_unscaled = scaler.inverse_transform(y_test)

# Print the evaluation metrics for the unscaled predictions
MAE_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE_unscaled = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('Unscaled Metrics')
print('MSE : ', MSE_unscaled)
print('RMSE : ', RMSE_unscaled)
print('MAE : ', MAE_unscaled)
print('MAPE : ', MAPE_unscaled)
print('R2 : ', R2_unscaled)

# Print the evaluation metrics for the scaled predictions
y_pred_scaled = y_pred_scaled.flatten()[::-1]
y_test_scaled = y_test.flatten()
MAE_scaled = mean_absolute_error(y_test_scaled, y_pred_scaled)
RMSE_scaled = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
R2_scaled = r2_score(y_test_scaled, y_pred_scaled)
MAPE_scaled = np.mean(np.abs((y_test_scaled - y_pred_scaled) / y_test_scaled)) * 100
MSE_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)

print('Scaled Metrics')
print('MSE : ', MSE_scaled)
print('RMSE : ', RMSE_scaled)
print('MAE : ', MAE_scaled)
print('MAPE : ', MAPE_scaled)
print('R2 : ', R2_scaled)

print('y_test_unscaled:')
print(y_test_unscaled)

print('y_pred_unscaled:')
print(y_pred_unscaled)


# Plot the actual vs predicted values for the unscaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_unscaled, 'go-', label='Actual')
plt.plot(y_pred_unscaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Unscaled)')
plt.legend()
plt.savefig('ActualPredictedValuesUnscaledM.pdf')
plt.show()

# Plot the actual vs predicted values for the scaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_scaled, 'go-', label='Actual')
plt.plot(y_pred_scaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Scaled)')
plt.legend()
plt.savefig('ActualPredictedValuesScaledM.pdf')
plt.show()

"""# Other (Draft and Wrong!)"""

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from tensorflow.keras.models import Sequential
from keras.layers import Dense, Conv1D, MaxPooling1D , Dropout , Flatten , BatchNormalization,LSTM
from tensorflow.keras.optimizers import SGD,Adam
from sklearn.metrics import confusion_matrix
import pandas as pd 
from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
import warnings
warnings.filterwarnings('ignore')

# Load the data from the csv file
df = pd.read_csv('/content/Monero.csv')

# Print the first two rows
print('A:')
print(df.head(5))

# def convert_vol(vol):
#     if vol.endswith('M'):
#         return int(float(vol[:-1]) * 1000000)
#     elif vol.endswith('K'):
#         return int(float(vol[:-1]) * 1000)
#     else:
#         return int(vol)

# df['Vol.'] = df['Vol.'].apply(convert_vol)
# df['Change %'] = df['Change %'].str.replace('%', '').astype(float)
# print('B:')
# print(df.head(5))

df=df[['Price']]
df.shape
df.head()

# Scale the data using MinMaxScaler with range (0,1)
scaler = MinMaxScaler(feature_range=(0,1))
df = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)
df.head()

def fun(data, lag):
    """
    A function that takes in data and a lag value and returns two arrays: x and y.
    x is an array of shape (k, lag, n), where k is the number of samples and n is the number of features.
    y is an array of shape (k, 1), where k is the number of samples.
    Each sample in x is a sequence of lag consecutive observations from data, and the corresponding value in y is the next observation.
    """
    k = len(data) - lag
    x = []
    y = []
    for i in range(k):
        x.append(data[i:i+lag])
        y.append(data[i+lag,:1])
    x = np.array(x)
    y = np.array(y)
    return x, y

# Reverse the order of the data array
data = np.array(df.iloc[::-1])

# Split the data into train and test sets
test = data[-37:]
train = data[:-36]

# Set the lag value
lag = 30

# Use the function fun to create x_train, y_train, x_test, and y_test arrays
x_train, y_train = fun(train, lag)
x_test, y_test = fun(test, lag)

# print x_test and y_test data
print("x_test data:\n", x_test)
print("y_test data:\n", y_test)

# print x_test and y_test shape
print("x_test shape:", x_test.shape)
print("y_test shape:", y_test.shape)

from tensorflow.keras.layers import GRU, LSTM, Dropout, Dense, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# Define the loss function
loss_fn = 'mse'

# Define the model
inputs = Input(shape=(30,1))
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.1)(gru)
gru = Dense(1, activation='relu')(gru)
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.1)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(1, activation='relu')(lstm)
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)
model = Model(inputs=inputs, outputs=outputs)

# Compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_fn, metrics=['mae','mse'])

# Fit the model with train data and validate with test data for 100 epochs
callback=EarlyStopping(min_delta=1e-5,patience=5)
history = model.fit(x_train, y_train, epochs=100, callbacks=[callback], validation_data=(x_test, y_test))

# Plot the MAE and MSE graphs
plt.plot(history.history['mae'], label='train')
plt.plot(history.history['val_mae'], label='test')
plt.title('Model MAE')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmae.pdf')
plt.show()

plt.plot(history.history['mse'], label='train')
plt.plot(history.history['val_mse'], label='test')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmse.pdf')
plt.show()

y_pred=model.predict(x_test)
fig = plt.figure(figsize=(8,3))
plt.plot(y_test[:7,0], label='y_test')
plt.plot(y_pred[:7,0], label='y_pred')
plt.xlabel("time step")
plt.title('PM2.5')
plt.legend()

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# Define and fit the scaler object on the training data
# scaler = MinMaxScaler()
# scaler.fit(x_train)

# Predict on the test data and unscale the predicted and test data
y_pred_scaled = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred_scaled[::-1])
y_test_unscaled = scaler.inverse_transform(y_test)

# Print the evaluation metrics for the unscaled predictions
MAE_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE_unscaled = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('Unscaled Metrics')
print('MAE : ', MAE_unscaled)
print('RMSE : ', RMSE_unscaled)
print('R2 : ', R2_unscaled)
print('MAPE : ', MAPE_unscaled)
print('MSE : ', MSE_unscaled)

# Print the evaluation metrics for the scaled predictions
y_pred_scaled = y_pred_scaled.flatten()[::-1]
y_test_scaled = y_test.flatten()
MAE_scaled = mean_absolute_error(y_test_scaled, y_pred_scaled)
RMSE_scaled = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
R2_scaled = r2_score(y_test_scaled, y_pred_scaled)
MAPE_scaled = np.mean(np.abs((y_test_scaled - y_pred_scaled) / y_test_scaled)) * 100
MSE_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)

print('Scaled Metrics')
print('MAE : ', MAE_scaled)
print('RMSE : ', RMSE_scaled)
print('R2 : ', R2_scaled)
print('MAPE : ', MAPE_scaled)
print('MSE : ', MSE_scaled)

# Plot the actual vs predicted values for the unscaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_unscaled, label='Actual')
plt.plot(y_pred_unscaled, label='Predicted')
plt.title('Actual vs Predicted Values (Unscaled)')
plt.legend()
plt.show()

# Plot the actual vs predicted values for the scaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_scaled, label='Actual')
plt.plot(y_pred_scaled, label='Predicted')
plt.title('Actual vs Predicted Values (Scaled)')
plt.legend()
plt.show()

print('y_test_unscaled:', y_test_unscaled)
print('y_pred_unscaled:', y_pred_unscaled)

y_test_unscaled

y_pred_unscaled

y_pred=model.predict(x_test)
MAE = mean_absolute_error(y_test,y_pred)
RMSE = np.sqrt(mean_squared_error(y_test, y_pred))
R2 = r2_score(y_test,y_pred)
print('MAE : ',MAE)
print('RMSE : ',RMSE)
print('R2 : ',R2)

y_pred_unscaled

y_test_unscaled

from sklearn.preprocessing import MinMaxScaler

# Define and fit the scaler object on the training data
scaler = MinMaxScaler()
scaler.fit(x_train.reshape(-1, x_train.shape[-1]))

# Predict on the test data and unscale the predicted and test data
y_pred = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()
y_test_unscaled = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()

# Plot actual vs predicted values
plt.plot(y_test_unscaled, label='Actual')
plt.plot(y_pred_unscaled, label='Predicted')
plt.title('Actual vs Predicted Values')
plt.legend()
plt.show()

# Calculate and print evaluation metrics
MAE = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2 = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('MAE : ', MAE)
print('RMSE : ', RMSE)
print('R2 : ', R2)
print('MAPE : ', MAPE)
print('MSE : ', MSE)

# predict on test data
y_pred = model.predict(x_test)

# inverse transform the predictions and actual values
y_pred_unscaled = scaler.inverse_transform(y_pred)
y_test_unscaled = scaler.inverse_transform(y_test)

# plot actual vs predicted values
plt.scatter(range(len(y_test_unscaled)), y_test_unscaled, label='Actual', alpha=0.5)
plt.scatter(range(len(y_pred_unscaled)), y_pred_unscaled, label='Predicted', alpha=0.5)
plt.title('Actual vs Predicted Values')
plt.legend()
plt.show()

# calculate and print evaluation metrics
MAE = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2 = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('MSE : ', MSE)
print('MAE : ', MAE)
print('RMSE : ', RMSE)
print('R2 : ', R2)
print('MAPE : ', MAPE)

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from tensorflow.keras.models import Sequential
from keras.layers import Dense, Conv1D, MaxPooling1D , Dropout , Flatten , BatchNormalization,LSTM
from tensorflow.keras.optimizers import SGD,Adam
from sklearn.metrics import confusion_matrix
import pandas as pd 
from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
import warnings
warnings.filterwarnings('ignore')

# Load the data from the csv file
df = pd.read_csv('/content/Litecoin.csv')

# Print the first two rows
print('A:')
print(df.head(5))

def convert_vol(vol):
    if vol.endswith('M'):
        return int(float(vol[:-1]) * 1000000)
    elif vol.endswith('K'):
        return int(float(vol[:-1]) * 1000)
    else:
        return int(vol)

df['Vol.'] = df['Vol.'].apply(convert_vol)
df['Change %'] = df['Change %'].str.replace('%', '').astype(float)
print('B:')
print(df.head(5))

df=df[['Price']]
df.shape
df.head()

# Scale the data using MinMaxScaler with range (0,1)
scaler = MinMaxScaler(feature_range=(0,1))
df = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)
df.head()

def fun(data, lag):
    """
    A function that takes in data and a lag value and returns two arrays: x and y.
    x is an array of shape (k, lag, n), where k is the number of samples and n is the number of features.
    y is an array of shape (k, 1), where k is the number of samples.
    Each sample in x is a sequence of lag consecutive observations from data, and the corresponding value in y is the next observation.
    """
    k = len(data) - lag
    x = []
    y = []
    for i in range(k):
        x.append(data[i:i+lag])
        y.append(data[i+lag,:1])
    x = np.array(x)
    y = np.array(y)
    return x, y

# Reverse the order of the data array
data = np.array(df.iloc[::-1])

# Split the data into train and test sets
test = data[-37:]
train = data[:-36]

# Set the lag value
lag = 30

# Use the function fun to create x_train, y_train, x_test, and y_test arrays
x_train, y_train = fun(train, lag)
x_test, y_test = fun(test, lag)

# print x_test and y_test data
print("x_test data:\n", x_test)
print("y_test data:\n", y_test)

# print x_test and y_test shape
print("x_test shape:", x_test.shape)
print("y_test shape:", y_test.shape)

from tensorflow.keras.layers import GRU, LSTM, Dropout, Dense, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# Define the loss function
loss_fn = 'mse'

# Define the model
inputs = Input(shape=(30,1))
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.1)(gru)
gru = Dense(1, activation='relu')(gru)
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.1)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(1, activation='relu')(lstm)
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)
model = Model(inputs=inputs, outputs=outputs)

# Compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_fn, metrics=['mae','mse'])

# Fit the model with train data and validate with test data for 100 epochs
callback=EarlyStopping(min_delta=1e-5,patience=5)
history = model.fit(x_train, y_train, epochs=100, callbacks=[callback], validation_data=(x_test, y_test))

# Plot the MAE and MSE graphs
plt.plot(history.history['mae'], label='train')
plt.plot(history.history['val_mae'], label='test')
plt.title('Model MAE')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmae.pdf')
plt.show()

plt.plot(history.history['mse'], label='train')
plt.plot(history.history['val_mse'], label='test')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmse.pdf')
plt.show()

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# Define and fit the scaler object on the training data
# scaler = MinMaxScaler()
# scaler.fit(x_train)

# Predict on the test data and unscale the predicted and test data
y_pred_scaled = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred_scaled[::-1])
y_test_unscaled = scaler.inverse_transform(y_test)

# Print the evaluation metrics for the unscaled predictions
MAE_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE_unscaled = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('Unscaled Metrics')
print('MAE : ', MAE_unscaled)
print('RMSE : ', RMSE_unscaled)
print('R2 : ', R2_unscaled)
print('MAPE : ', MAPE_unscaled)
print('MSE : ', MSE_unscaled)

# Print the evaluation metrics for the scaled predictions
y_pred_scaled = y_pred_scaled.flatten()[::-1]
y_test_scaled = y_test.flatten()
MAE_scaled = mean_absolute_error(y_test_scaled, y_pred_scaled)
RMSE_scaled = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
R2_scaled = r2_score(y_test_scaled, y_pred_scaled)
MAPE_scaled = np.mean(np.abs((y_test_scaled - y_pred_scaled) / y_test_scaled)) * 100
MSE_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)

print('Scaled Metrics')
print('MAE : ', MAE_scaled)
print('RMSE : ', RMSE_scaled)
print('R2 : ', R2_scaled)
print('MAPE : ', MAPE_scaled)
print('MSE : ', MSE_scaled)

# Plot the actual vs predicted values for the unscaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_unscaled, label='Actual')
plt.plot(y_pred_unscaled, label='Predicted')
plt.title('Actual vs Predicted Values (Unscaled)')
plt.legend()
plt.show()

# Plot the actual vs predicted values for the scaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_scaled, label='Actual')
plt.plot(y_pred_scaled, label='Predicted')
plt.title('Actual vs Predicted Values (Scaled)')
plt.legend()
plt.show()

print('y_test_unscaled:', y_test_unscaled)
print('y_pred_unscaled:', y_pred_unscaled)

y_test_unscaled

y_pred_unscaled

y_pred=model.predict(x_test)
MAE = mean_absolute_error(y_test,y_pred)
RMSE = np.sqrt(mean_squared_error(y_test, y_pred))
R2 = r2_score(y_test,y_pred)
print('MAE : ',MAE)
print('RMSE : ',RMSE)
print('R2 : ',R2)

y_pred_unscaled

y_test_unscaled

from sklearn.preprocessing import MinMaxScaler

# Define and fit the scaler object on the training data
scaler = MinMaxScaler()
scaler.fit(x_train.reshape(-1, x_train.shape[-1]))

# Predict on the test data and unscale the predicted and test data
y_pred = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()
y_test_unscaled = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()

# Plot actual vs predicted values
plt.plot(y_test_unscaled, label='Actual')
plt.plot(y_pred_unscaled, label='Predicted')
plt.title('Actual vs Predicted Values')
plt.legend()
plt.show()

# Calculate and print evaluation metrics
MAE = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2 = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('MAE : ', MAE)
print('RMSE : ', RMSE)
print('R2 : ', R2)
print('MAPE : ', MAPE)
print('MSE : ', MSE)

# predict on test data
y_pred = model.predict(x_test)

# inverse transform the predictions and actual values
y_pred_unscaled = scaler.inverse_transform(y_pred)
y_test_unscaled = scaler.inverse_transform(y_test)

# plot actual vs predicted values
plt.scatter(range(len(y_test_unscaled)), y_test_unscaled, label='Actual', alpha=0.5)
plt.scatter(range(len(y_pred_unscaled)), y_pred_unscaled, label='Predicted', alpha=0.5)
plt.title('Actual vs Predicted Values')
plt.legend()
plt.show()

# calculate and print evaluation metrics
MAE = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2 = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('MSE : ', MSE)
print('MAE : ', MAE)
print('RMSE : ', RMSE)
print('R2 : ', R2)
print('MAPE : ', MAPE)

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from tensorflow.keras.models import Sequential
from keras.layers import Dense, Conv1D, MaxPooling1D , Dropout , Flatten , BatchNormalization,LSTM
from tensorflow.keras.optimizers import SGD,Adam
from sklearn.metrics import confusion_matrix
import pandas as pd 
from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
import warnings
warnings.filterwarnings('ignore')

# Load the data from the csv file
df = pd.read_csv('/content/Litecoin.csv')

# Print the first two rows
print('A:')
print(df.head(5))

def convert_vol(vol):
    if vol.endswith('M'):
        return int(float(vol[:-1]) * 1000000)
    elif vol.endswith('K'):
        return int(float(vol[:-1]) * 1000)
    else:
        return int(vol)

df['Vol.'] = df['Vol.'].apply(convert_vol)
df['Change %'] = df['Change %'].str.replace('%', '').astype(float)
print('B:')
print(df.head(5))

df=df[['Price']]
df.shape
df.head()

# Scale the data using MinMaxScaler with range (0,1)
scaler = MinMaxScaler(feature_range=(0,1))
df = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)
df.head()

def fun(data, lag):
    """
    A function that takes in data and a lag value and returns two arrays: x and y.
    x is an array of shape (k, lag, n), where k is the number of samples and n is the number of features.
    y is an array of shape (k, 1), where k is the number of samples.
    Each sample in x is a sequence of lag consecutive observations from data, and the corresponding value in y is the next observation.
    """
    k = len(data) - lag
    x = []
    y = []
    for i in range(k):
        x.append(data[i:i+lag])
        y.append(data[i+lag,:1])
    x = np.array(x)
    y = np.array(y)
    return x, y

# Reverse the order of the data array
data = np.array(df.iloc[::-1])

# Split the data into train and test sets
test = data[-33:]
train = data[:-32]

# Set the lag value
lag = 30

# Use the function fun to create x_train, y_train, x_test, and y_test arrays
x_train, y_train = fun(train, lag)
x_test, y_test = fun(test, lag)

# print x_test and y_test data
print("x_test data:\n", x_test)
print("y_test data:\n", y_test)

# print x_test and y_test shape
print("x_test shape:", x_test.shape)
print("y_test shape:", y_test.shape)

from tensorflow.keras.layers import GRU, LSTM, Dropout, Dense, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# Define the loss function
loss_fn = 'mse'

# Define the model
inputs = Input(shape=(30,1))
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.1)(gru)
gru = Dense(1, activation='relu')(gru)
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.1)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(1, activation='relu')(lstm)
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)
model = Model(inputs=inputs, outputs=outputs)

# Compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_fn, metrics=['mae','mse'])

# Fit the model with train data and validate with test data for 100 epochs
callback=EarlyStopping(min_delta=1e-5,patience=5)
history = model.fit(x_train, y_train, epochs=100, callbacks=[callback], validation_data=(x_test, y_test))

# Plot the MAE and MSE graphs
plt.plot(history.history['mae'], label='train')
plt.plot(history.history['val_mae'], label='test')
plt.title('Model MAE')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmae.pdf')
plt.show()

plt.plot(history.history['mse'], label='train')
plt.plot(history.history['val_mse'], label='test')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmse.pdf')
plt.show()

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# Define and fit the scaler object on the training data
# scaler = MinMaxScaler()
# scaler.fit(x_train)

# Predict on the test data and unscale the predicted and test data
y_pred_scaled = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred_scaled[::-1])
y_test_unscaled = scaler.inverse_transform(y_test)

# Print the evaluation metrics for the unscaled predictions
MAE_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE_unscaled = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('Unscaled Metrics')
print('MAE : ', MAE_unscaled)
print('RMSE : ', RMSE_unscaled)
print('R2 : ', R2_unscaled)
print('MAPE : ', MAPE_unscaled)
print('MSE : ', MSE_unscaled)

# Print the evaluation metrics for the scaled predictions
y_pred_scaled = y_pred_scaled.flatten()[::-1]
y_test_scaled = y_test.flatten()
MAE_scaled = mean_absolute_error(y_test_scaled, y_pred_scaled)
RMSE_scaled = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
R2_scaled = r2_score(y_test_scaled, y_pred_scaled)
MAPE_scaled = np.mean(np.abs((y_test_scaled - y_pred_scaled) / y_test_scaled)) * 100
MSE_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)

print('Scaled Metrics')
print('MAE : ', MAE_scaled)
print('RMSE : ', RMSE_scaled)
print('R2 : ', R2_scaled)
print('MAPE : ', MAPE_scaled)
print('MSE : ', MSE_scaled)

# Plot the actual vs predicted values for the unscaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_unscaled, label='Actual')
plt.plot(y_pred_unscaled, label='Predicted')
plt.title('Actual vs Predicted Values (Unscaled)')
plt.legend()
plt.show()

# Plot the actual vs predicted values for the scaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_scaled, label='Actual')
plt.plot(y_pred_scaled, label='Predicted')
plt.title('Actual vs Predicted Values (Scaled)')
plt.legend()
plt.show()

print('y_test_unscaled:', y_test_unscaled)
print('y_pred_unscaled:', y_pred_unscaled)

y_test_unscaled

y_pred_unscaled

y_pred=model.predict(x_test)
MAE = mean_absolute_error(y_test,y_pred)
RMSE = np.sqrt(mean_squared_error(y_test, y_pred))
R2 = r2_score(y_test,y_pred)
print('MAE : ',MAE)
print('RMSE : ',RMSE)
print('R2 : ',R2)

y_pred_unscaled

y_test_unscaled

from sklearn.preprocessing import MinMaxScaler

# Define and fit the scaler object on the training data
scaler = MinMaxScaler()
scaler.fit(x_train.reshape(-1, x_train.shape[-1]))

# Predict on the test data and unscale the predicted and test data
y_pred = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()
y_test_unscaled = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()

# Plot actual vs predicted values
plt.plot(y_test_unscaled, label='Actual')
plt.plot(y_pred_unscaled, label='Predicted')
plt.title('Actual vs Predicted Values')
plt.legend()
plt.show()

# Calculate and print evaluation metrics
MAE = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2 = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('MAE : ', MAE)
print('RMSE : ', RMSE)
print('R2 : ', R2)
print('MAPE : ', MAPE)
print('MSE : ', MSE)

# predict on test data
y_pred = model.predict(x_test)

# inverse transform the predictions and actual values
y_pred_unscaled = scaler.inverse_transform(y_pred)
y_test_unscaled = scaler.inverse_transform(y_test)

# plot actual vs predicted values
plt.scatter(range(len(y_test_unscaled)), y_test_unscaled, label='Actual', alpha=0.5)
plt.scatter(range(len(y_pred_unscaled)), y_pred_unscaled, label='Predicted', alpha=0.5)
plt.title('Actual vs Predicted Values')
plt.legend()
plt.show()

# calculate and print evaluation metrics
MAE = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2 = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('MSE : ', MSE)
print('MAE : ', MAE)
print('RMSE : ', RMSE)
print('R2 : ', R2)
print('MAPE : ', MAPE)

from tensorflow.keras.layers import GRU, LSTM, Dropout, Dense, Input, concatenate
from tensorflow.keras.models import Model

inputs = Input(shape=(30,1))

# GRU Network
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.2)(gru)
gru = Dense(1, activation='relu')(gru)

# LSTM Network
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.2)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(1, activation='relu')(lstm)

# Combine GRU and LSTM networks
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)

model = Model(inputs=inputs, outputs=outputs)
model.summary()

# compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001),loss=loss_fn)

# fit the model with train data and validate with test data for 100 epochs
history = model.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test))

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Model
from keras.layers import Input, GRU, LSTM, Dense, Dropout, concatenate
from keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error
from matplotlib.backends.backend_pdf import PdfPages
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, GRU, Dropout, Dense, concatenate
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt

# Load data from CSV file
data = pd.read_csv('/content/Litecoin.csv')

# Filter the data to include only the dates within the specified range
data = data.loc[(data['Date'] >= 'Aug 24, 2016') & (data['Date'] <= 'Feb 22, 2020')]

# Select the primary feature for training
training_data = data['Price'].values.reshape(-1, 1)

# Normalize the training data to scale values between 0 and 1
scaler = MinMaxScaler(feature_range=(0, 1))
training_data_normalized = scaler.fit_transform(training_data)

# Define the input window length (number of past days to use for prediction)
input_window_length = 30

# Use the PROCESS_DATA algorithm to create input/output samples
def process_data(data, input_window_length):
    Dx = []
    Dy = []
    n = len(data)
    for i in range(n):
        end_index = i + input_window_length
        if end_index > n-1:
            break
        temp_X = data[i:end_index, :]
        temp_Y = data[end_index, 0]
        Dx.append(temp_X)
        Dy.append(temp_Y)
    Dx = np.array(Dx)
    Dy = np.array(Dy)
    return (Dx, Dy)

# Create input/output samples using the training data
train_X, train_Y = process_data(training_data_normalized, input_window_length)

# Define the model
inputs = Input(shape=(input_window_length, 1))

# GRU Network
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.25)(gru)
gru = Dense(30, activation='relu')(gru)

# LSTM Network
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.25)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(30, activation='relu')(lstm)

# Combine GRU and LSTM networks
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)

model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer='adam', loss='mse', metrics=['mae','mse'])

# Train the model
history = model.fit(train_X, train_Y, epochs=100)

# Plot MAE over epochs
mae_history = history.history['mae']
plt.plot(range(1, len(mae_history)+1), mae_history, label='Training MAE')
plt.title('Training MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()
plt.savefig('maeplot22.pdf')
plt.show()

# Plot MSE over epochs
mse_history = history.history['loss']
plt.plot(range(1, len(mse_history)+1), mse_history, label='Training MSE')
plt.title('Training MSE')
plt.xlabel('Epoch')
plt.ylabel('MSE')
plt.legend()
plt.savefig('mmseplot22.pdf')
plt.show()

# Get the last 30 days' data
last_30_days = data['Price'].head(input_window_length).values.reshape(-1, 1)

# Normalize the data
last_30_days_normalized = scaler.transform(last_30_days)

# Reshape the data to match the input shape of the model
last_30_days_normalized_reshaped = last_30_days_normalized.reshape(1, input_window_length, 1)

# Use the trained model to predict the price for the next day
predicted_price_normalized = model.predict(last_30_days_normalized_reshaped)

# Invert the normalization to get the predicted price in the original scale
predicted_price = scaler.inverse_transform(predicted_price_normalized)

# Print last inputs, actual output and predicted output
print("Last 30 days' data:\n", last_30_days)
print("Actual price for the next day:", data['Price'].head(1).values[0])
print("Predicted price for the next day:", predicted_price[0][0])

# Calculate evaluation metrics
actual_price = data['Price'].head(1).values[0]
mse = mean_squared_error([actual_price], [predicted_price[0][0]])
rmse = np.sqrt(mse)
mae = mean_absolute_error([actual_price], [predicted_price[0][0]])
mape = mean_absolute_percentage_error([actual_price], [predicted_price[0][0]])

# Print evaluation metrics
print("MSE:", mse)
print("RMSE:", rmse)
print("MAE:", mae)
print("MAPE:", mape)

import pandas as pd

# Load the data from the csv file
df = pd.read_csv('/content/Litecoin.csv')

# Print the first two rows
print('A:')
print(df.head(5))

def convert_vol(vol):
    if vol.endswith('M'):
        return int(float(vol[:-1]) * 1000000)
    elif vol.endswith('K'):
        return int(float(vol[:-1]) * 1000)
    else:
        return int(vol)

df['Vol.'] = df['Vol.'].apply(convert_vol)
df['Change %'] = df['Change %'].str.replace('%', '').astype(float)
print('B:')
print(df.head(5))

# Load data from CSV file
data = pd.read_csv('/content/Litecoin.csv')

# Filter the data to include only the dates within the specified range
data = data.loc[(data['Date'] >= 'Aug 24, 2016') & (data['Date'] <= 'Feb 23, 2020')]

# Select the primary feature for training
training_data = data['Price'].values.reshape(-1, 1)

# Normalize the training data to scale values between 0 and 1
scaler = MinMaxScaler(feature_range=(0, 1))
training_data_normalized = scaler.fit_transform(training_data)

# Define the input window length (number of past days to use for prediction)
input_window_length = 30

# Use the PROCESS_DATA algorithm to create input/output samples
def process_data(data, input_window_length):
    Dx = []
    Dy = []
    n = len(data)
    for i in range(n):
        end_index = i + input_window_length
        if end_index > n-1:
            break
        temp_X = data[i:end_index, :]
        temp_Y = data[end_index, 0]
        Dx.append(temp_X)
        Dy.append(temp_Y)
    Dx = np.array(Dx)
    Dy = np.array(Dy)
    return (Dx, Dy)

# Create input/output samples using the training data
train_X, train_Y = process_data(training_data_normalized, input_window_length)

# Predict the price for the next day using the last 30 inputs
last_30_inputs = train_X[-1].reshape(1, input_window_length, 1)
predicted_price = scaler.inverse_transform(model.predict(last_30_inputs))[0][0]

# Print the predicted price
print('Predicted price for the next day:', predicted_price)

import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Model
from keras.layers import Input, GRU, LSTM, Dense, Dropout, concatenate
from keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error
from matplotlib.backends.backend_pdf import PdfPages
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, GRU, Dropout, Dense, concatenate
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt

# Load data from CSV file
data = pd.read_csv('/content/Litecoin.csv')

# Filter the data to include only the dates within the specified range
# data = data.loc[(data['Date'] >= 'Aug 24, 2016') & (data['Date'] <= 'Feb 22, 2020')]

# Select the primary feature for training
training_data = data['Price'].values.reshape(-1, 1)

# Normalize the training data to scale values between 0 and 1
scaler = MinMaxScaler(feature_range=(0, 1))
training_data_normalized = scaler.fit_transform(training_data)

# Define the input window length (number of past days to use for prediction)
input_window_length = 30

# Use the PROCESS_DATA algorithm to create input/output samples
def process_data(data, input_window_length):
    Dx = []
    Dy = []
    n = len(data)
    for i in range(n):
        end_index = i + input_window_length
        if end_index > n-1:
            break
        temp_X = data[i:end_index, :]
        temp_Y = data[end_index, 0]
        Dx.append(temp_X)
        Dy.append(temp_Y)
    Dx = np.array(Dx)
    Dy = np.array(Dy)
    return (Dx, Dy)

# Create input/output samples using the training data
train_X, train_Y = process_data(training_data_normalized, input_window_length)

import keras

# Load the trained model
model = keras.models.load_model('modelSc1LitecoinHM.h5')

# Get the last 30 input values from the test set
last_inputs = train_X[1].reshape(1, input_window_length, 1)

# Make a prediction for the next day
next_day_price_normalized = model.predict(last_inputs)

# Rescale the predicted price to the original range
next_day_price = scaler.inverse_transform(next_day_price_normalized)

print('Predicted price for February 23, 2020:', next_day_price[0, 0])

# Get the last 30 inputs without scaling
# last_inputs = scaler.inverse_transform(train_X[-1])

# Print the last 30 inputs without scaling
print("Last 30 inputs without scaling:")
for i, val in enumerate(train_X):
    print("Day {}: {}".format(i+1, val))

# Load the saved model
model = Model(inputs=inputs, outputs=outputs)
model.load_weights('modelSc1LitecoinHM.h5')

# Get the last 30 days of data from the input data
last_30_days = training_data_normalized[-30:]

# Reshape the data to match the input shape of the model
last_30_days = last_30_days.reshape(1, 30, 1)

# Use the trained model to predict the price for the next day
predicted_price = model.predict(last_30_days)

# Denormalize the predicted price
predicted_price = scaler.inverse_transform(predicted_price)

# Print the predicted price for the next day
print('Predicted price for the next day:', predicted_price[0][0])

# Use the trained model to predict the prices for the test set
predicted_prices = model.predict(test_X)

# Denormalize the predicted prices and actual prices
predicted_prices = scaler.inverse_transform(predicted_prices)
actual_prices = scaler.inverse_transform(test_Y.reshape(-1, 1))

# Calculate MSE, RMSE, MAE, and MAPE for the test set
mse = mean_squared_error(actual_prices, predicted_prices)
rmse = np.sqrt(mse)
mae = mean_absolute_error(actual_prices, predicted_prices)
mape = mean_absolute_percentage_error(actual_prices, predicted_prices)

# Print the evaluation metrics
print('MSE:', mse)
print('RMSE:', rmse)
print('MAE:', mae)
print('MAPE:', mape)

actual_prices

predicted_price

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from keras.models import Model
from keras.layers import Input, Dense, LSTM, GRU, Dropout, concatenate

# load data
df = pd.read_csv('/content/Litecoin.csv')

# extract relevant data
df = df.loc[df['Date'] >= 'Aug 24, 2016']
df = df.loc[df['Date'] <= 'Feb 22, 2020']
df = df[['Price']]

# scale data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(df.values)

# create training data
lookback = 30
X_train = []
y_train = []
for i in range(lookback, len(scaled_data)):
    X_train.append(scaled_data[i-lookback:i, 0])
    y_train.append(scaled_data[i, 0])
X_train, y_train = np.array(X_train), np.array(y_train)
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

# create model
inputs = Input(shape=(lookback, 1))
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.2)(gru)
gru = Dense(30, activation='relu')(gru)
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.2)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(30, activation='relu')(lstm)
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)
model = Model(inputs=inputs, outputs=outputs)

# compile model
model.compile(optimizer='adam', loss='mean_squared_error')

# train model
model.fit(X_train, y_train, epochs=50, batch_size=32)

# predict February 23, 2020 price
last_60_days = df.tail(lookback).values
last_60_days_scaled = scaler.transform(last_60_days)
X_test = []
X_test.append(last_60_days_scaled)
X_test = np.array(X_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
predicted_price_scaled = model.predict(X_test)
predicted_price = scaler.inverse_transform(predicted_price_scaled)
print(predicted_price)

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from keras.models import Model
from keras.layers import Input, Dense, LSTM, GRU, Dropout, concatenate

# load data
df = pd.read_csv('/content/Litecoin.csv')

# extract relevant data
df = df.loc[df['Date'] >= 'Aug 24, 2016']
df = df.loc[df['Date'] <= 'Feb 22, 2020']
df = df[['Price']]

# scale data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(df.values)

# create training data
lookback = 30
X_train = []
y_train = []
for i in range(lookback, len(scaled_data)):
    X_train.append(scaled_data[i-lookback:i, 0])
    y_train.append(scaled_data[i, 0])
X_train, y_train = np.array(X_train), np.array(y_train)
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

# create model
inputs = Input(shape=(lookback, 1))
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.2)(gru)
gru = Dense(30, activation='relu')(gru)
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.2)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(30, activation='relu')(lstm)
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)
model = Model(inputs=inputs, outputs=outputs)

# compile model
model.compile(optimizer='adam', loss='mean_squared_error')

# train model
model.fit(X_train, y_train, epochs=50, batch_size=32)

# predict February 23, 2020 price
last_61_days = df.tail(lookback+1).values
last_60_days_scaled = scaler.transform(last_61_days[:-1])
X_test = []
X_test.append(last_60_days_scaled)
X_test = np.array(X_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
predicted_price_scaled = model.predict(X_test)
predicted_price = scaler.inverse_transform(predicted_price_scaled)
print(predicted_price)

# Step 1: Import the necessary libraries
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, GRU, Dropout

# Step 2: Load the data
df = pd.read_csv('/content/Litecoin.csv')
price_data = df.loc[df['Date'] <= 'Feb 22, 2020', 'Price'].values.reshape(-1, 1)

# Step 3: Min-Max normalization
scaler = MinMaxScaler(feature_range=(0, 1))
normalized_price_data = scaler.fit_transform(price_data)

# Step 4: Create input-output pairs
def process_data(data, n_steps):
    Dx, Dy = [], []
    n = len(data)
    for i in range(n):
        end_ix = i + n_steps
        if end_ix > n-1:
            break
        Dx.append(data[i:end_ix, :])
        Dy.append(data[end_ix, 0])
    return np.array(Dx), np.array(Dy)

n_steps = 30
Dx, Dy = process_data(normalized_price_data, n_steps)
# X_train, X_test, y_train, y_test = train_test_split(Dx, Dy, test_size=0.1, random_state=42)

# Step 5: Define the model
model = Sequential()
model.add(GRU(30, return_sequences=True, input_shape=(n_steps, 1)))
model.add(Dropout(0.2))
model.add(Dense(10))
model.add(LSTM(50, return_sequences=False))
model.add(Dense(1))

# Step 6: Train the model
from tensorflow.keras.optimizers import Adam

learning_rate = 0.01
optimizer = Adam(learning_rate=learning_rate)

model.compile(optimizer=optimizer, loss='mean_squared_error')
history = model.fit(Dx, Dy, epochs=100, batch_size=30)

# Step 7: Predict the price for February 23, 2020
last_30_days = normalized_price_data[-30:]
X_pred = np.array(last_30_days).reshape(1, n_steps, 1)
y_pred = model.predict(X_pred)
y_pred_actual = scaler.inverse_transform(y_pred)
print("Predicted Price on February 23, 2020: ", y_pred_actual[0][0])

# Step 7: Predict the price for February 23, 2020
last_30_days = normalized_price_data[:30]
X_pred = np.array(last_30_days).reshape(1, n_steps, 1)
y_pred = model.predict(X_pred)
y_pred_actual = scaler.inverse_transform(y_pred)
print("Predicted Price on February 23, 2020: ", y_pred_actual[0][0])

# Step 9: Predict the price for the next day
last_30_days = normalized_price_data[:30]
X_pred = np.array(last_30_days).reshape(1, n_steps, 1)
y_pred = model.predict(X_pred)
y_pred_actual = scaler.inverse_transform(y_pred)
print("Actual Price on February 23, 2020: ", df.iloc[0]['Price'])
print("Predicted Price on February 23, 2020: ", y_pred_actual[0][0])

# Step 1: Import the necessary libraries
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, GRU, Dropout
import matplotlib.pyplot as plt

# Step 2: Load the data
df = pd.read_csv('/content/Litecoin.csv')
price_data = df['Price'].values.reshape(-1, 1)

# Step 3: Min-Max normalization
scaler = MinMaxScaler(feature_range=(0, 1))
normalized_price_data = scaler.fit_transform(price_data)

# Step 4: Create input-output pairs
# def process_data(data, n_steps):
#     Dx, Dy = [], []
#     n = len(data)
#     for i in range(n):
#         end_ix = i + n_steps
#         if end_ix > n-1:
#             break
#         Dx.append(data[i:end_ix, :])
#         Dy.append(data[end_ix, 0])
#     return np.array(Dx), np.array(Dy)

# Step 4: Create input-output pairs
def process_data(data, n_steps):
    Dx, Dy = [], []
    n = len(data)
    for i in range(n - n_steps):
        Dx.append(data[i:i + n_steps])
        Dy.append(data[i + n_steps])
    return np.array(Dx), np.array(Dy)


n_steps = 30
Dx, Dy = process_data(normalized_price_data, n_steps)
X_train, X_test, y_train, y_test = train_test_split(Dx, Dy, test_size=0.2, random_state=42)

# Step 5: Define the model
model = Sequential()
model.add(GRU(30, return_sequences=True, input_shape=(n_steps, 1)))
model.add(Dropout(0.2))
model.add(Dense(10))
model.add(LSTM(50, return_sequences=False))
model.add(Dense(1))

# Step 6: Train the model
model.compile(optimizer='adam', loss='mse')
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))

# Step 7: Make predictions
y_pred = model.predict(X_test)

# Step 8: Calculate and plot MSE and MAE
mse = np.mean(np.square(y_test - y_pred))
mae = np.mean(np.abs(y_test - y_pred))

plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='test')
plt.title('MSE: {:.4f}, MAE: {:.4f}'.format(mse, mae))
plt.legend()
plt.show()

# Step 1: Import the necessary libraries
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, GRU, Dropout
import matplotlib.pyplot as plt

# Step 2: Load the data
df = pd.read_csv('/content/Litecoin.csv')
price_data = df['Price'].values.reshape(-1, 1)

# Step 3: Min-Max normalization
scaler = MinMaxScaler(feature_range=(0, 1))
normalized_price_data = scaler.fit_transform(price_data)

# Step 4: Create input-output pairs
def process_data(data, n_steps):
    Dx, Dy = [], []
    n = len(data)
    for i in range(n):
        end_ix = i + n_steps
        if end_ix > n-1:
            break
        Dx.append(data[i:end_ix, :])
        Dy.append(data[end_ix, 0])
    return np.array(Dx), np.array(Dy)


n_steps = 30
Dx, Dy = process_data(normalized_price_data, n_steps)
X_train, X_test, y_train, y_test = train_test_split(Dx, Dy, test_size=0.2, random_state=42)

# Step 5: Define the model
model = Sequential()
model.add(GRU(30, return_sequences=True, input_shape=(n_steps, 1)))
model.add(Dropout(0.2))
model.add(Dense(10))
model.add(LSTM(50, return_sequences=False))
model.add(Dense(1))

# Step 6: Train the model
model.compile(optimizer='adam', loss='mse')
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))

# Step 7: Make predictions
y_pred = model.predict(X_test)

# Step 8: Calculate and plot MSE and MAE
mse = np.mean(np.square(y_test - y_pred))
mae = np.mean(np.abs(y_test - y_pred))

plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='test')
plt.title('MSE: {:.4f}, MAE: {:.4f}'.format(mse, mae))
plt.legend()
plt.show()

# Step 9: Predict the price for the next day
last_30_days = normalized_price_data[:30]
X_pred = np.array(last_30_days).reshape(1, n_steps, 1)
y_pred = model.predict(X_pred)
y_pred_actual = scaler.inverse_transform(y_pred)
print("Actual Price on February 23, 2020: ", df.iloc[0]['Price'])
print("Predicted Price on February 23, 2020: ", y_pred_actual[0][0])

# Step 9: Predict the price for the next day
last_30_days = normalized_price_data[:30]
X_pred = np.array(last_30_days).reshape(1, n_steps, 1)
y_pred = model.predict(X_pred)
y_pred_actual = scaler.inverse_transform(y_pred)
print("Actual Price on February 23, 2020: ", df.iloc[0]['Price'])
print("Predicted Price on February 23, 2020: ", y_pred_actual[0][0])

# Step 1: Import the necessary libraries
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, GRU, Dropout
import matplotlib.pyplot as plt

# Step 2: Load the data
df = pd.read_csv('/content/Litecoin.csv')
price_data = df['Price'].values.reshape(-1, 1)

# Step 3: Min-Max normalization
scaler = MinMaxScaler(feature_range=(0, 1))
normalized_price_data = scaler.fit_transform(price_data)

# Step 4: Create input-output pairs
def process_data(data, n_steps):
    Dx, Dy = [], []
    n = len(data)
    for i in range(n):
        end_ix = i + n_steps
        if end_ix > n-1:
            break
        Dx.append(data[i:end_ix, :])
        Dy.append(data[end_ix, 0])
    return np.array(Dx), np.array(Dy)


n_steps = 30
Dx, Dy = process_data(normalized_price_data, n_steps)
X_train, X_test, y_train, y_test = train_test_split(Dx, Dy, test_size=0.2, random_state=42)

# Step 5: Define the model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(n_steps, 1)))
model.add(Dense(1))

# Step 6: Train the model
model.compile(optimizer='adam', loss='mse')
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))

# Step 7: Make predictions
y_pred = model.predict(X_test)

# Step 8: Calculate and plot MSE and MAE
mse = np.mean(np.square(y_test - y_pred))
mae = np.mean(np.abs(y_test - y_pred))

plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='test')
plt.title('MSE: {:.4f}, MAE: {:.4f}'.format(mse, mae))
plt.legend()
plt.show()



# Step 9: Predict the price for the next day
last_30_days = normalized_price_data[:30]
X_pred = np.array(last_30_days).reshape(1, n_steps, 1)
y_pred = model.predict(X_pred)
y_pred_actual = scaler.inverse_transform(y_pred)
print("Actual Price on February 23, 2020: ", df.iloc[0]['Price'])
print("Predicted Price on February 23, 2020: ", y_pred_actual[0][0])

import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# Read the Litecoin data from CSV file
df = pd.read_csv('/content/Litecoin.csv')

# Select only the 'Price' column
data = df['Price'].values.reshape(-1, 1)

# Scale the data using Min-Max Normalization
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)

# Prepare the data for input to the model
def process_data(data, n_steps):
    Dx, Dy = [], []
    for i in range(len(data)):
        end_ix = i + n_steps
        if end_ix >= len(data):
            break
        Dx.append(data[i:end_ix, 0])
        Dy.append(data[end_ix, 0])
    return np.array(Dx), np.array(Dy)

# Prepare the data with a window size of 30
n_steps = 30
Dx, Dy = process_data(scaled_data, n_steps)

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, GRU, Concatenate

# Define the input shape
input_shape = (n_steps, 1)

# Define the GRU network
gru_input = Input(shape=input_shape)
gru_layer = GRU(30)(gru_input)
gru_dropout = Dropout(0.2)(gru_layer)
gru_output = Dense(64, activation='relu')(gru_dropout)

# Define the LSTM network
lstm_input = Input(shape=input_shape)
lstm_layer1 = LSTM(30, return_sequences=True)(lstm_input)
lstm_dropout1 = Dropout(0.2)(lstm_layer1)
lstm_layer2 = LSTM(50)(lstm_dropout1)
lstm_dropout2 = Dropout(0.2)(lstm_layer2)
lstm_output = Dense(64, activation='relu')(lstm_dropout2)

# Concatenate the output of both networks
concat_output = Concatenate()([gru_output, lstm_output])
final_output = Dense(1, activation='linear')(concat_output)

# Define the model
model = Model(inputs=[gru_input, lstm_input], outputs=final_output)

# Compile the model
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Train the model for 100 epochs
history = model.fit([Dx, Dx], Dy, epochs=100, batch_size=32, validation_split=0.2)

# Plot the mean squared error and mean absolute error
import matplotlib.pyplot as plt

mse = history.history['loss']
val_mse = history.history['val_loss']
mae = history.history['mae']
val_mae = history.history['val_mae']
epochs = range(1, len(mse) + 1)

plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs, mse, 'b', label='Training MSE')
plt.plot(epochs, val_mse, 'r', label='Validation MSE')
plt.title('Training and Validation MSE')
plt.xlabel('Epochs')
plt.ylabel('MSE')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(epochs
, mae, 'b', label='Training MAE')
plt.plot(epochs, val_mae, 'r', label='Validation MAE')
plt.title('Training and Validation MAE')
plt.xlabel('Epochs')
plt.ylabel('MAE')
plt.legend()

plt.show()

"""### Monero"""

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from tensorflow.keras.models import Sequential
from keras.layers import Dense, Conv1D, MaxPooling1D , Dropout , Flatten , BatchNormalization,LSTM
from tensorflow.keras.optimizers import SGD,Adam
from sklearn.metrics import confusion_matrix
import pandas as pd 
from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
import warnings
warnings.filterwarnings('ignore')

# Load the data from the csv file
df = pd.read_csv('/content/Monero.csv')

# Print the first two rows
print('A:')
print(df.head(5))

df=df[['Price']]
df.shape
df.head()

# Scale the data using MinMaxScaler with range (0,1)
scaler = MinMaxScaler(feature_range=(0,1))
df = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)
df.head()

def fun(data, lag):
    """
    A function that takes in data and a lag value and returns two arrays: x and y.
    x is an array of shape (k, lag, n), where k is the number of samples and n is the number of features.
    y is an array of shape (k, 1), where k is the number of samples.
    Each sample in x is a sequence of lag consecutive observations from data, and the corresponding value in y is the next observation.
    """
    k = len(data) - lag
    x = []
    y = []
    for i in range(k):
        x.append(data[i:i+lag])
        y.append(data[i+lag,:1])
    x = np.array(x)
    y = np.array(y)
    return x, y

# Reverse the order of the data array
data = np.array(df.iloc[::-1])

# Set the number of data points to predict
prediction_window = 1

# Set the number of previous data points to use for prediction
lag = 30

# Split the data into train and test sets
test_start_index = len(data) - prediction_window - lag
test = data[test_start_index:]
train = data[:test_start_index]

# Use the function fun to create x_train, y_train, x_test, and y_test arrays
x_train, y_train = fun(train, lag)
x_test, y_test = fun(test, lag)

from tensorflow.keras.layers import GRU, LSTM, Dropout, Dense, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# Define the loss function
loss_fn = 'mse'

# Define the model
inputs = Input(shape=(30,1))
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.25)(gru)
gru = Dense(1, activation='relu')(gru)
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.25)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(1, activation='relu')(lstm)
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)
model = Model(inputs=inputs, outputs=outputs)

# Compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_fn, metrics=['mae','mse'])

# Fit the model with train data and validate with test data for 100 epochs
callback=EarlyStopping(min_delta=1e-5,patience=10)
history = model.fit(x_train, y_train, epochs=100, callbacks=[callback], validation_data=(x_test, y_test))

# Plot the MAE and MSE graphs
plt.plot(history.history['mae'], label='train')
plt.plot(history.history['val_mae'], label='test')
plt.title('Model MAE')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmaeM.pdf')
plt.show()

plt.plot(history.history['mse'], label='train')
plt.plot(history.history['val_mse'], label='test')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmseM.pdf')
plt.show()

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# Define and fit the scaler object on the training data
# scaler = MinMaxScaler()
# scaler.fit(x_train)

# Predict on the test data and unscale the predicted and test data
y_pred_scaled = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred_scaled[::-1])
y_test_unscaled = scaler.inverse_transform(y_test)

# Print the evaluation metrics for the unscaled predictions
MAE_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE_unscaled = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('Unscaled Metrics')
print('MSE : ', MSE_unscaled)
print('RMSE : ', RMSE_unscaled)
print('MAE : ', MAE_unscaled)
print('MAPE : ', MAPE_unscaled)
print('R2 : ', R2_unscaled)

# Print the evaluation metrics for the scaled predictions
y_pred_scaled = y_pred_scaled.flatten()[::-1]
y_test_scaled = y_test.flatten()
MAE_scaled = mean_absolute_error(y_test_scaled, y_pred_scaled)
RMSE_scaled = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
R2_scaled = r2_score(y_test_scaled, y_pred_scaled)
MAPE_scaled = np.mean(np.abs((y_test_scaled - y_pred_scaled) / y_test_scaled)) * 100
MSE_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)

print('Scaled Metrics')
print('MSE : ', MSE_scaled)
print('RMSE : ', RMSE_scaled)
print('MAE : ', MAE_scaled)
print('MAPE : ', MAPE_scaled)
print('R2 : ', R2_scaled)

print('y_test_unscaled:')
print(y_test_unscaled)

print('y_pred_unscaled:')
print(y_pred_unscaled)

# Plot the actual vs predicted values for the unscaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_unscaled, 'go-', label='Actual')
plt.plot(y_pred_unscaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Unscaled)')
plt.legend()
plt.savefig('ActualPredictedValuesUnscaledM.pdf')
plt.show()

# Plot the actual vs predicted values for the scaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_scaled, 'go-', label='Actual')
plt.plot(y_pred_scaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Scaled)')
plt.legend()
plt.savefig('ActualPredictedValuesScaledM.pdf')
plt.show()

"""### Litecoin"""

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from tensorflow.keras.models import Sequential
from keras.layers import Dense, Conv1D, MaxPooling1D , Dropout , Flatten , BatchNormalization,LSTM
from tensorflow.keras.optimizers import SGD,Adam
from sklearn.metrics import confusion_matrix
import pandas as pd 
from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
import warnings
warnings.filterwarnings('ignore')

# Load the data from the csv file
df = pd.read_csv('/content/Litecoin.csv')

# Print the first two rows
print('A:')
print(df.head(5))

def convert_vol(vol):
    if vol.endswith('M'):
        return int(float(vol[:-1]) * 1000000)
    elif vol.endswith('K'):
        return int(float(vol[:-1]) * 1000)
    else:
        return int(vol)

df['Vol.'] = df['Vol.'].apply(convert_vol)
df['Change %'] = df['Change %'].str.replace('%', '').astype(float)
print('B:')
print(df.head(5))

df=df[['Price']]
df.shape
df.head()

# Scale the data using MinMaxScaler with range (0,1)
scaler = MinMaxScaler(feature_range=(0,1))
df = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)
df.head()

def fun(data, lag):
    """
    A function that takes in data and a lag value and returns two arrays: x and y.
    x is an array of shape (k, lag, n), where k is the number of samples and n is the number of features.
    y is an array of shape (k, 1), where k is the number of samples.
    Each sample in x is a sequence of lag consecutive observations from data, and the corresponding value in y is the next observation.
    """
    k = len(data) - lag
    x = []
    y = []
    for i in range(k):
        x.append(data[i:i+lag])
        y.append(data[i+lag,:1])
    x = np.array(x)
    y = np.array(y)
    return x, y

# Reverse the order of the data array
data = np.array(df.iloc[::-1])

# Set the number of data points to predict
prediction_window = 1

# Set the number of previous data points to use for prediction
lag = 30

# Split the data into train and test sets
test_start_index = len(data) - prediction_window - lag
test = data[test_start_index:]
train = data[:test_start_index]

# Use the function fun to create x_train, y_train, x_test, and y_test arrays
x_train, y_train = fun(train, lag)
x_test, y_test = fun(test, lag)

from tensorflow.keras.layers import GRU, LSTM, Dropout, Dense, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# Define the loss function
loss_fn = 'mse'

# Define the model
inputs = Input(shape=(30,1))
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.25)(gru)
gru = Dense(1, activation='relu')(gru)
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.25)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(1, activation='relu')(lstm)
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)
model = Model(inputs=inputs, outputs=outputs)

# Compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_fn, metrics=['mae','mse'])

# Fit the model with train data and validate with test data for 100 epochs
callback=EarlyStopping(min_delta=1e-5,patience=10)
history = model.fit(x_train, y_train, epochs=100, callbacks=[callback], validation_data=(x_test, y_test))

# Plot the MAE and MSE graphs
plt.plot(history.history['mae'], label='train')
plt.plot(history.history['val_mae'], label='test')
plt.title('Model MAE')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmae.pdf')
plt.show()

plt.plot(history.history['mse'], label='train')
plt.plot(history.history['val_mse'], label='test')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmse.pdf')
plt.show()

# Scale the data using MinMaxScaler with range (0,1)
scaler = MinMaxScaler(feature_range=(0,1))
df = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)

# Define input window length and prediction window length
input_window_length = 30
prediction_window_length = 1

# Reverse the order of the data array
data = np.array(df.iloc[::-1])

# Split the data into train and test sets
test_start_index = len(data) - prediction_window_length - input_window_length
test = data[test_start_index:]
train = data[:test_start_index]

# Process the data using the given algorithm
def predict_price(Dx, Dy, P_Window):
    R = trained_model
    P_Values = []
    l = np.append(Dx[-1], Dy[-1])
    Dx = np.delete(Dx, 0, axis=0)
    for i in range(P_Window):
        P_l = R.predict(np.array([l[:input_window_length]]))[0][0]
        P_Values.append(P_l)
        l = np.append(l[input_window_length:], P_l)
    return P_Values

x_train, y_train = process_data(train, input_window_length)
x_test, y_test = process_data(test, input_window_length)

# Define the loss function
loss_fn = 'mse'

# Define the model
inputs = Input(shape=(input_window_length,1))
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.25)(gru)
gru = Dense(1, activation='relu')(gru)
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.25)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(1, activation='relu')(lstm)
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)
model = Model(inputs=inputs, outputs=outputs)

# Compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_fn, metrics=['mae','mse'])

# Fit the model with train data and validate with test data for 100 epochs
callback=EarlyStopping(min_delta=1e-5,patience=10)
history = model.fit(x_train, y_train, epochs=100, callbacks=[callback], validation_data=(x_test, y_test))

# Use the trained model to predict prices
predicted_prices = []
for i in range(len(x_test)):
    Dx = x_test[i]
    Dy = y_test[i]
    P_Values = predict_price(Dx, Dy, prediction_window_length)
    predicted_prices.append(P_Values)

# Convert the predicted prices and test prices to unscaled values
predicted_prices_unscaled = []
y_test_unscaled = []
for i in range(len(predicted_prices)):
    predicted_prices_unscaled.append(scaler.inverse_transform(np.array(predicted_prices[i]).reshape(-1, 1)))
    y_test_unscaled.append(scaler.inverse_transform(np.array(y_test[i]).reshape(-1, 1)))

# Plot the actual vs predicted values
plt.figure(figsize=(10, 6))
for i in range(len(predicted_prices_unscaled)):
    plt.scatter(range(len(predicted_prices_unscaled[i])), predicted_prices_unscaled[i], color='red')
    plt.plot(range(len(y_test_unscaled[i])), y_test_unscaled[i], color='green', linestyle='--')
plt.title('Actual vs Predicted Values')
plt.legend()
plt.savefig('ActualPredictedValuesScaled.pdf')
plt.show()

# Process the data using the given algorithm
def predict_price(Dx, Dy, P_Window):
    R = model
    P_Values = []
    l = np.append(Dx[-1], Dy[-1])
    Dx = np.delete(Dx, 0, axis=0)
    for i in range(P_Window):
        P_l = R.predict(np.array([l[:input_window_length]]))[0][0]
        P_Values.append(P_l)
        l = np.append(l[input_window_length:], P_l)
    return P_Values

# Use the trained model to predict prices
predicted_prices = []
for i in range(len(x_test)):
    Dx = x_test[i]
    Dy = y_test[i]
    P_Values = predict_price(Dx, Dy, prediction_window_length)
    predicted_prices.append(P_Values)

# Convert the predicted prices and test prices to unscaled values
predicted_prices_unscaled = []
y_test_unscaled = []
for i in range(len(predicted_prices)):
    predicted_prices_unscaled.append(scaler.inverse_transform(np.array(predicted_prices[i]).reshape(-1, 1)))
    y_test_unscaled.append(scaler.inverse_transform(np.array(y_test[i]).reshape(-1, 1)))

# Plot the actual vs predicted values
plt.figure(figsize=(10, 6))
for i in range(len(predicted_prices_unscaled)):
    plt.scatter(range(len(predicted_prices_unscaled[i])), predicted_prices_unscaled[i], color='red')
    plt.plot(range(len(y_test_unscaled[i])), y_test_unscaled[i], color='green', linestyle='--')
plt.title('Actual vs Predicted Values')
plt.legend()
plt.savefig('ActualPredictedValuesScaled.pdf')
plt.show()

def predict_price(Dx, Dy, P_Window, model):
    """
    A function that takes in Dx (features), Dy (target), P_Window (prediction window length) and trained model
    and returns an array P_Values of predicted prices.
    """
    # Create a DataFrame R with the given features and target
    R = pd.concat([Dx, Dy], axis=1)

    # Initialize an empty array P_Values
    P_Values = []

    # Get the last value of Dx and append it to l
    l = Dx.iloc[-1]

    # Delete the first value of Dx
    Dx = Dx.iloc[1:]

    # Append the last value of Dy to l
    l = l.append(Dy.iloc[-1])

    # Predict the next P_Window values
    for i in range(P_Window):
        # Append the predicted value to P_Values
        P_Values.append(model.predict(l.values.reshape(1,-1))[0,0])

        # Delete the first value of l
        l = l.iloc[1:]

        # Append the predicted value to l
        l = l.append(pd.DataFrame(P_Values[-1], index=[Dy.columns[-1]], columns=[l.columns[-1]]))

    # Return the predicted values
    return np.array(P_Values)

# Pass the features, target, prediction window, and trained model to the function
P_Values = predict_price(Dx, Dy, P_Window, model)

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# Define and fit the scaler object on the training data
# scaler = MinMaxScaler()
# scaler.fit(x_train)

# Predict on the test data and unscale the predicted and test data
y_pred_scaled = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred_scaled[::-1])
y_test_unscaled = scaler.inverse_transform(y_test)

# Print the evaluation metrics for the unscaled predictions
MAE_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE_unscaled = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('Unscaled Metrics')
print('MSE : ', MSE_unscaled)
print('RMSE : ', RMSE_unscaled)
print('MAE : ', MAE_unscaled)
print('MAPE : ', MAPE_unscaled)
print('R2 : ', R2_unscaled)

# Print the evaluation metrics for the scaled predictions
y_pred_scaled = y_pred_scaled.flatten()[::-1]
y_test_scaled = y_test.flatten()
MAE_scaled = mean_absolute_error(y_test_scaled, y_pred_scaled)
RMSE_scaled = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
R2_scaled = r2_score(y_test_scaled, y_pred_scaled)
MAPE_scaled = np.mean(np.abs((y_test_scaled - y_pred_scaled) / y_test_scaled)) * 100
MSE_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)

print('Scaled Metrics')
print('MSE : ', MSE_scaled)
print('RMSE : ', RMSE_scaled)
print('MAE : ', MAE_scaled)
print('MAPE : ', MAPE_scaled)
print('R2 : ', R2_scaled)

print('y_test_unscaled:')
print(y_test_unscaled)

print('y_pred_unscaled:')
print(y_pred_unscaled)

# Plot the actual vs predicted values for the unscaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_unscaled, 'go-', label='Actual')
plt.plot(y_pred_unscaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Unscaled)')
plt.legend()
plt.savefig('ActualPredictedValuesUnscaled.pdf')
plt.show()

# Plot the actual vs predicted values for the scaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_scaled, 'go-', label='Actual')
plt.plot(y_pred_scaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Scaled)')
plt.legend()
plt.savefig('ActualPredictedValuesScaled.pdf')
plt.show()

"""### New Section"""

from tensorflow.keras.layers import GRU, LSTM, Dropout, Dense, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# Define the loss function
loss_fn = 'mse'

# Define the model
inputs = Input(shape=(30,1))
gru = GRU(30, activation='relu', return_sequences=False)(inputs)
gru = Dropout(0.25)(gru)
gru = Dense(1, activation='relu')(gru)
lstm = LSTM(30, activation='relu', return_sequences=True)(inputs)
lstm = Dropout(0.25)(lstm)
lstm = LSTM(50, activation='relu')(lstm)
lstm = Dense(1, activation='relu')(lstm)
combined = concatenate([gru, lstm])
outputs = Dense(1)(combined)
model = Model(inputs=inputs, outputs=outputs)

# Compile the model with Adam optimizer and defined loss function
model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_fn, metrics=['mae','mse'])

# Fit the model with train data and validate with test data for 100 epochs
callback=EarlyStopping(min_delta=1e-5,patience=10)
history = model.fit(x_train, y_train, epochs=100, callbacks=[callback], validation_data=(x_test, y_test))

# Plot the MAE and MSE graphs
plt.plot(history.history['mae'], label='train')
plt.plot(history.history['val_mae'], label='test')
plt.title('Model MAE')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmaeM.pdf')
plt.show()

plt.plot(history.history['mse'], label='train')
plt.plot(history.history['val_mse'], label='test')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('lossmseM.pdf')
plt.show()

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# Define and fit the scaler object on the training data
# scaler = MinMaxScaler()
# scaler.fit(x_train)

# Predict on the test data and unscale the predicted and test data
y_pred_scaled = model.predict(x_test)
y_pred_unscaled = scaler.inverse_transform(y_pred_scaled[::-1])
y_test_unscaled = scaler.inverse_transform(y_test)

# Print the evaluation metrics for the unscaled predictions
MAE_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
RMSE_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))
R2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)
MAPE_unscaled = np.mean(np.abs((y_test_unscaled - y_pred_unscaled) / y_test_unscaled)) * 100
MSE_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print('Unscaled Metrics')
print('MSE : ', MSE_unscaled)
print('RMSE : ', RMSE_unscaled)
print('MAE : ', MAE_unscaled)
print('MAPE : ', MAPE_unscaled)
print('R2 : ', R2_unscaled)

# Print the evaluation metrics for the scaled predictions
y_pred_scaled = y_pred_scaled.flatten()[::-1]
y_test_scaled = y_test.flatten()
MAE_scaled = mean_absolute_error(y_test_scaled, y_pred_scaled)
RMSE_scaled = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
R2_scaled = r2_score(y_test_scaled, y_pred_scaled)
MAPE_scaled = np.mean(np.abs((y_test_scaled - y_pred_scaled) / y_test_scaled)) * 100
MSE_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)

print('Scaled Metrics')
print('MSE : ', MSE_scaled)
print('RMSE : ', RMSE_scaled)
print('MAE : ', MAE_scaled)
print('MAPE : ', MAPE_scaled)
print('R2 : ', R2_scaled)

print('y_test_unscaled:')
print(y_test_unscaled)

print('y_pred_unscaled:')
print(y_pred_unscaled)

# Plot the actual vs predicted values for the unscaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_unscaled, 'go-', label='Actual')
plt.plot(y_pred_unscaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Unscaled)')
plt.legend()
plt.savefig('ActualPredictedValuesUnscaledM.pdf')
plt.show()

# Plot the actual vs predicted values for the scaled data
plt.figure(figsize=(10, 6))
plt.plot(y_test_scaled, 'go-', label='Actual')
plt.plot(y_pred_scaled, 'r*--', label='Predicted')
plt.title('Actual vs Predicted Values (Scaled)')
plt.legend()
plt.savefig('ActualPredictedValuesScaledM.pdf')
plt.show()